{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-05T14:05:48.421815Z","iopub.execute_input":"2025-01-05T14:05:48.422142Z","iopub.status.idle":"2025-01-05T14:05:48.724741Z","shell.execute_reply.started":"2025-01-05T14:05:48.422112Z","shell.execute_reply":"2025-01-05T14:05:48.723793Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset\nimport re","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T14:05:48.725797Z","iopub.execute_input":"2025-01-05T14:05:48.726149Z","iopub.status.idle":"2025-01-05T14:05:49.260969Z","shell.execute_reply.started":"2025-01-05T14:05:48.726124Z","shell.execute_reply":"2025-01-05T14:05:49.260078Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"\ndataset=load_dataset(\"imdb\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T14:05:49.262523Z","iopub.execute_input":"2025-01-05T14:05:49.262950Z","iopub.status.idle":"2025-01-05T14:05:52.585252Z","shell.execute_reply.started":"2025-01-05T14:05:49.262910Z","shell.execute_reply":"2025-01-05T14:05:52.584453Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T14:05:52.586215Z","iopub.execute_input":"2025-01-05T14:05:52.586641Z","iopub.status.idle":"2025-01-05T14:05:52.594335Z","shell.execute_reply.started":"2025-01-05T14:05:52.586612Z","shell.execute_reply":"2025-01-05T14:05:52.593569Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 25000\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 25000\n    })\n    unsupervised: Dataset({\n        features: ['text', 'label'],\n        num_rows: 50000\n    })\n})"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"length=[len(x.split()) for x in dataset['train']['text']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T14:05:52.594884Z","iopub.execute_input":"2025-01-05T14:05:52.595113Z","iopub.status.idle":"2025-01-05T14:05:52.971960Z","shell.execute_reply.started":"2025-01-05T14:05:52.595091Z","shell.execute_reply":"2025-01-05T14:05:52.971253Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import collections\nimport matplotlib.pyplot as plt\nfrom collections import Counter\ncount =Counter(length)\n\nkeys=list(count.keys())\nvalues=list(count.values())\nplt.bar(keys,values)\nplt.xlabel(\"length\")\nplt.ylabel(\"counts\")\nplt.xticks(range(0,max(length),200))\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T14:05:52.972741Z","iopub.execute_input":"2025-01-05T14:05:52.972985Z","iopub.status.idle":"2025-01-05T14:05:54.272931Z","shell.execute_reply.started":"2025-01-05T14:05:52.972963Z","shell.execute_reply":"2025-01-05T14:05:54.272045Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"def cleaned_text(text):\n        text=re.sub(r'<.*?>',\"\",text)\n        text=re.sub(r'[^a-zA-z\\s]',\"\",text)\n        text=text.lower()\n        text=re.sub(r'\\s+',\" \",text).strip()\n        return text\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T14:05:54.273669Z","iopub.execute_input":"2025-01-05T14:05:54.273900Z","iopub.status.idle":"2025-01-05T14:05:54.277730Z","shell.execute_reply.started":"2025-01-05T14:05:54.273878Z","shell.execute_reply":"2025-01-05T14:05:54.276783Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# train_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T14:05:54.279836Z","iopub.execute_input":"2025-01-05T14:05:54.280044Z","iopub.status.idle":"2025-01-05T14:05:54.293081Z","shell.execute_reply.started":"2025-01-05T14:05:54.280025Z","shell.execute_reply":"2025-01-05T14:05:54.292378Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# train_cleaned = [cleaned_text(text) for text in train_data['text']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T14:05:54.294895Z","iopub.execute_input":"2025-01-05T14:05:54.295091Z","iopub.status.idle":"2025-01-05T14:05:54.308601Z","shell.execute_reply.started":"2025-01-05T14:05:54.295074Z","shell.execute_reply":"2025-01-05T14:05:54.307778Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# train_cleaned[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T14:05:54.309419Z","iopub.execute_input":"2025-01-05T14:05:54.309674Z","iopub.status.idle":"2025-01-05T14:05:54.327697Z","shell.execute_reply.started":"2025-01-05T14:05:54.309641Z","shell.execute_reply":"2025-01-05T14:05:54.326905Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_data=dataset[\"train\"]\ntest_data=dataset[\"test\"]\ndef create_validation_split(data,val_size=0.1,seed=42):\n    train_idx,val_idx=train_test_split(range(len(data)),\n                                    test_size=val_size,\n                                    stratify=data['label'],\n                                    random_state=seed\n                                    )\n    return train_idx,val_idx\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T14:05:54.328541Z","iopub.execute_input":"2025-01-05T14:05:54.328742Z","iopub.status.idle":"2025-01-05T14:05:54.635864Z","shell.execute_reply.started":"2025-01-05T14:05:54.328723Z","shell.execute_reply":"2025-01-05T14:05:54.635118Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"train_idx,val_idx=create_validation_split(train_data)\ntrain_data=train_data.select(train_idx)\nvalidation_data=dataset['train'].select(val_idx)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T14:05:54.636668Z","iopub.execute_input":"2025-01-05T14:05:54.637042Z","iopub.status.idle":"2025-01-05T14:05:54.717440Z","shell.execute_reply.started":"2025-01-05T14:05:54.637020Z","shell.execute_reply":"2025-01-05T14:05:54.716520Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import re\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForSequenceClassification\nfrom torch.utils.data import Dataset,DataLoader\ntokenizer=AutoTokenizer.from_pretrained(\"bert-base-uncased\")\nmodel=AutoModelForSequenceClassification.from_pretrained(\n    'distilbert-base-uncased',\n    num_labels=2\n)\n\n\nclass IMDPdataset(Dataset):\n    def __init__(self,text,label,tokenizer):\n        self.text=text\n        self.label=label\n        self.tokenizer=tokenizer\n    def __len__(self):\n        return len(self.text)\n\n    @staticmethod\n    def cleaned_text(text):\n        text=re.sub(r'<.*?>',\"\",text)\n        text=re.sub(r'[^a-zA-z\\s]',\"\",text)\n        text=text.lower()\n        text=re.sub(r'\\s+',\" \",text).strip()\n        return text\n    \n    def __getitem__(self,idx):\n        cleaned=self.cleaned_text(self.text[idx])\n        x=tokenizer(cleaned,\n        padding=\"max_length\",\n        max_length=512,\n        truncation=True,\n        return_tensors=\"pt\"\n    )\n        return{\"input_ids\":x['input_ids'].squeeze(0),\n               \"attention_mask\":x['attention_mask'].squeeze(0),\n               \"label\":self.label[idx]}\n        \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T14:05:54.718267Z","iopub.execute_input":"2025-01-05T14:05:54.718523Z","iopub.status.idle":"2025-01-05T14:05:57.381826Z","shell.execute_reply.started":"2025-01-05T14:05:54.718501Z","shell.execute_reply":"2025-01-05T14:05:57.381087Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"train_dataset=IMDPdataset(train_data['text'],train_data['label'],tokenizer)\ntest_dataset=IMDPdataset(test_data['text'],test_data['label'],tokenizer)\nval_dataset=IMDPdataset(validation_data['text'],validation_data['label'],tokenizer)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T14:52:09.214347Z","iopub.execute_input":"2025-01-05T14:52:09.214762Z","iopub.status.idle":"2025-01-05T14:52:09.544044Z","shell.execute_reply.started":"2025-01-05T14:52:09.214731Z","shell.execute_reply":"2025-01-05T14:52:09.543381Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"for i in range(3):\n    sample=next(iter(train_dataset))\n    print(sample['input_ids'])\n    print(sample['attention_mask'])\n    print(sample['label'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T14:05:57.942440Z","iopub.execute_input":"2025-01-05T14:05:57.942758Z","iopub.status.idle":"2025-01-05T14:05:57.965227Z","shell.execute_reply.started":"2025-01-05T14:05:57.942724Z","shell.execute_reply":"2025-01-05T14:05:57.964477Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"tensor([  101,  2632, 11239,  1996, 18594,  2003,  2028,  2919,  1998,  4895,\n        11263, 10695,  2100,  4333,  4038,  1996, 10984,  1997,  1996, 14308,\n        21354,  2003,  3294,  2125,  2023,  2003,  1996,  2785,  1997,  8562,\n         2007,  3056, 10071,  2008,  2191,  2017,  4687,  2065,  2027,  2890,\n         4011,  2000,  2022,  6057,  2030,  2025,  2174,  1996,  5025,  3737,\n         1997,  1996,  2143,  2003, 22537,  2023,  2003, 10915, 10523,  2005,\n         2143, 23176,  2015,  3701,  2138,  2049,  2028,  1997,  1996,  5700,\n         4973,  1997,  5637,  5988,  1996,  2364,  2839,  1997,  2632, 11239,\n         2003,  2019,  1041, 16020, 19269,  3124,  3772,  2172,  2066,  1996,\n        12991, 27086,  6090,  6508,  2691,  1999,  2116,  2220,  3152,  1996,\n         2143,  2038,  1996, 24004, 20200,  7729,  2691,  1997,  1996,  2051,\n         2632, 11239,  1996, 18594,  2003,  3492,  9643,  2021, 17160,  2013,\n         1037,  3439, 21386,   102,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0])\ntensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0])\n0\ntensor([  101,  2632, 11239,  1996, 18594,  2003,  2028,  2919,  1998,  4895,\n        11263, 10695,  2100,  4333,  4038,  1996, 10984,  1997,  1996, 14308,\n        21354,  2003,  3294,  2125,  2023,  2003,  1996,  2785,  1997,  8562,\n         2007,  3056, 10071,  2008,  2191,  2017,  4687,  2065,  2027,  2890,\n         4011,  2000,  2022,  6057,  2030,  2025,  2174,  1996,  5025,  3737,\n         1997,  1996,  2143,  2003, 22537,  2023,  2003, 10915, 10523,  2005,\n         2143, 23176,  2015,  3701,  2138,  2049,  2028,  1997,  1996,  5700,\n         4973,  1997,  5637,  5988,  1996,  2364,  2839,  1997,  2632, 11239,\n         2003,  2019,  1041, 16020, 19269,  3124,  3772,  2172,  2066,  1996,\n        12991, 27086,  6090,  6508,  2691,  1999,  2116,  2220,  3152,  1996,\n         2143,  2038,  1996, 24004, 20200,  7729,  2691,  1997,  1996,  2051,\n         2632, 11239,  1996, 18594,  2003,  3492,  9643,  2021, 17160,  2013,\n         1037,  3439, 21386,   102,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0])\ntensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0])\n0\ntensor([  101,  2632, 11239,  1996, 18594,  2003,  2028,  2919,  1998,  4895,\n        11263, 10695,  2100,  4333,  4038,  1996, 10984,  1997,  1996, 14308,\n        21354,  2003,  3294,  2125,  2023,  2003,  1996,  2785,  1997,  8562,\n         2007,  3056, 10071,  2008,  2191,  2017,  4687,  2065,  2027,  2890,\n         4011,  2000,  2022,  6057,  2030,  2025,  2174,  1996,  5025,  3737,\n         1997,  1996,  2143,  2003, 22537,  2023,  2003, 10915, 10523,  2005,\n         2143, 23176,  2015,  3701,  2138,  2049,  2028,  1997,  1996,  5700,\n         4973,  1997,  5637,  5988,  1996,  2364,  2839,  1997,  2632, 11239,\n         2003,  2019,  1041, 16020, 19269,  3124,  3772,  2172,  2066,  1996,\n        12991, 27086,  6090,  6508,  2691,  1999,  2116,  2220,  3152,  1996,\n         2143,  2038,  1996, 24004, 20200,  7729,  2691,  1997,  1996,  2051,\n         2632, 11239,  1996, 18594,  2003,  3492,  9643,  2021, 17160,  2013,\n         1037,  3439, 21386,   102,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0])\ntensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0])\n0\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# !pip uninstall -y peft huggingface_hub\n\n# # Install specific versions that work together\n# !pip install huggingface_hub==0.16.4\n# !pip install peft","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T14:05:57.965986Z","iopub.execute_input":"2025-01-05T14:05:57.966230Z","iopub.status.idle":"2025-01-05T14:05:57.969237Z","shell.execute_reply.started":"2025-01-05T14:05:57.966198Z","shell.execute_reply":"2025-01-05T14:05:57.968510Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nfrom peft import get_peft_model, LoraConfig, TaskType","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T14:05:57.970048Z","iopub.execute_input":"2025-01-05T14:05:57.970384Z","iopub.status.idle":"2025-01-05T14:05:58.044663Z","shell.execute_reply.started":"2025-01-05T14:05:57.970352Z","shell.execute_reply":"2025-01-05T14:05:58.043793Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"model=AutoModelForSequenceClassification.from_pretrained(\n    'distilbert-base-uncased',\n    num_labels=2\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T14:05:58.045544Z","iopub.execute_input":"2025-01-05T14:05:58.045745Z","iopub.status.idle":"2025-01-05T14:05:58.169647Z","shell.execute_reply.started":"2025-01-05T14:05:58.045727Z","shell.execute_reply":"2025-01-05T14:05:58.168901Z"}},"outputs":[{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=32,\n    lora_alpha=64,\n    target_modules=[\"q_lin\", \"k_lin\", \"v_lin\"],\n    lora_dropout=0.1,\n    bias=\"none\",\n    task_type=TaskType.SEQ_CLS\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T14:05:58.170541Z","iopub.execute_input":"2025-01-05T14:05:58.170747Z","iopub.status.idle":"2025-01-05T14:05:58.174839Z","shell.execute_reply.started":"2025-01-05T14:05:58.170728Z","shell.execute_reply":"2025-01-05T14:05:58.173933Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T14:05:58.175909Z","iopub.execute_input":"2025-01-05T14:05:58.176233Z","iopub.status.idle":"2025-01-05T14:05:58.193110Z","shell.execute_reply.started":"2025-01-05T14:05:58.176201Z","shell.execute_reply":"2025-01-05T14:05:58.192264Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"peftmodel=get_peft_model(model,lora_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T14:05:58.194002Z","iopub.execute_input":"2025-01-05T14:05:58.194232Z","iopub.status.idle":"2025-01-05T14:05:58.237552Z","shell.execute_reply.started":"2025-01-05T14:05:58.194199Z","shell.execute_reply":"2025-01-05T14:05:58.236688Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"!pip install wandb\nimport wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T14:05:58.238374Z","iopub.execute_input":"2025-01-05T14:05:58.238640Z","iopub.status.idle":"2025-01-05T14:06:02.115315Z","shell.execute_reply.started":"2025-01-05T14:05:58.238608Z","shell.execute_reply":"2025-01-05T14:06:02.114661Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.19.1)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\nRequirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.9.2)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.2)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (2.23.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"wandb.login(key=\"5160da7d6632bf129ee82d18c94a11388dc6bcb6\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T14:17:51.173376Z","iopub.execute_input":"2025-01-05T14:17:51.173683Z","iopub.status.idle":"2025-01-05T14:17:51.413403Z","shell.execute_reply.started":"2025-01-05T14:17:51.173662Z","shell.execute_reply":"2025-01-05T14:17:51.412683Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbasem-yasser\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\nimport torch\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nnum_training_steps = len(train_dataset) * 3 // 16  # (dataset_size * epochs) // batch_size\nwarmup_steps = num_training_steps // 10  # 10% of total steps\n\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results1\",\n    num_train_epochs=3,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    warmup_steps=warmup_steps,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=10,\n    eval_strategy=\"epoch\",    \n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"accuracy\",\n    report_to=\"wandb\",              \n    run_name=\"imdb-sentiment-run1\"   \n)\n\n# 2. Define metrics function\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n    acc = accuracy_score(labels, preds)\n    return {\n        'accuracy': acc,\n        'f1': f1,\n        'precision': precision,\n        'recall': recall\n    }\n\n# 3. Initialize Trainer\ntrainer = Trainer(\n    model=peftmodel,                         \n    args=training_args,                  \n    train_dataset=train_dataset,         \n    eval_dataset=val_dataset,            \n    compute_metrics=compute_metrics,      \n)\n\ntrainer.train(resume_from_checkpoint=True)\neval_results = trainer.evaluate(test_dataset)\nprint(eval_results)\n\ntrainer.save_model(\"./final_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T14:54:44.749650Z","iopub.execute_input":"2025-01-05T14:54:44.749979Z","iopub.status.idle":"2025-01-05T14:59:11.191273Z","shell.execute_reply.started":"2025-01-05T14:54:44.749950Z","shell.execute_reply":"2025-01-05T14:59:11.190471Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3098: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4221' max='4221' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4221/4221 : < :, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1563/1563 04:25]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.2240704447031021, 'eval_accuracy': 0.9138, 'eval_f1': 0.9145688800792864, 'eval_precision': 0.906483300589391, 'eval_recall': 0.9228, 'eval_runtime': 265.5671, 'eval_samples_per_second': 94.138, 'eval_steps_per_second': 5.886, 'epoch': 3.0}\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}