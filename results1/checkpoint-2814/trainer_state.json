{
  "best_metric": 0.8976,
  "best_model_checkpoint": "./results1/checkpoint-2814",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 2814,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007107320540156361,
      "grad_norm": 0.8181204199790955,
      "learning_rate": 1.187648456057007e-06,
      "loss": 0.7004,
      "step": 10
    },
    {
      "epoch": 0.014214641080312722,
      "grad_norm": 1.0279542207717896,
      "learning_rate": 2.375296912114014e-06,
      "loss": 0.6958,
      "step": 20
    },
    {
      "epoch": 0.021321961620469083,
      "grad_norm": 0.8940870761871338,
      "learning_rate": 3.5629453681710215e-06,
      "loss": 0.6875,
      "step": 30
    },
    {
      "epoch": 0.028429282160625444,
      "grad_norm": 0.857053279876709,
      "learning_rate": 4.750593824228028e-06,
      "loss": 0.6893,
      "step": 40
    },
    {
      "epoch": 0.03553660270078181,
      "grad_norm": 1.266706109046936,
      "learning_rate": 5.938242280285035e-06,
      "loss": 0.6863,
      "step": 50
    },
    {
      "epoch": 0.042643923240938165,
      "grad_norm": 0.9493836164474487,
      "learning_rate": 7.125890736342043e-06,
      "loss": 0.6844,
      "step": 60
    },
    {
      "epoch": 0.04975124378109453,
      "grad_norm": 0.9968581795692444,
      "learning_rate": 8.31353919239905e-06,
      "loss": 0.6927,
      "step": 70
    },
    {
      "epoch": 0.05685856432125089,
      "grad_norm": 0.7703754305839539,
      "learning_rate": 9.501187648456057e-06,
      "loss": 0.6892,
      "step": 80
    },
    {
      "epoch": 0.06396588486140725,
      "grad_norm": 1.190040111541748,
      "learning_rate": 1.0688836104513065e-05,
      "loss": 0.6839,
      "step": 90
    },
    {
      "epoch": 0.07107320540156362,
      "grad_norm": 1.089756965637207,
      "learning_rate": 1.187648456057007e-05,
      "loss": 0.6867,
      "step": 100
    },
    {
      "epoch": 0.07818052594171997,
      "grad_norm": 0.7433860898017883,
      "learning_rate": 1.3064133016627078e-05,
      "loss": 0.6729,
      "step": 110
    },
    {
      "epoch": 0.08528784648187633,
      "grad_norm": 0.9344238638877869,
      "learning_rate": 1.4251781472684086e-05,
      "loss": 0.6764,
      "step": 120
    },
    {
      "epoch": 0.0923951670220327,
      "grad_norm": 1.026196002960205,
      "learning_rate": 1.5439429928741092e-05,
      "loss": 0.6824,
      "step": 130
    },
    {
      "epoch": 0.09950248756218906,
      "grad_norm": 1.1045241355895996,
      "learning_rate": 1.66270783847981e-05,
      "loss": 0.6691,
      "step": 140
    },
    {
      "epoch": 0.10660980810234541,
      "grad_norm": 0.8705831170082092,
      "learning_rate": 1.7814726840855108e-05,
      "loss": 0.6713,
      "step": 150
    },
    {
      "epoch": 0.11371712864250177,
      "grad_norm": 1.0659359693527222,
      "learning_rate": 1.9002375296912114e-05,
      "loss": 0.6594,
      "step": 160
    },
    {
      "epoch": 0.12082444918265814,
      "grad_norm": 1.5173131227493286,
      "learning_rate": 2.0190023752969123e-05,
      "loss": 0.6474,
      "step": 170
    },
    {
      "epoch": 0.1279317697228145,
      "grad_norm": 2.0305075645446777,
      "learning_rate": 2.137767220902613e-05,
      "loss": 0.6248,
      "step": 180
    },
    {
      "epoch": 0.13503909026297087,
      "grad_norm": 1.3181008100509644,
      "learning_rate": 2.2565320665083135e-05,
      "loss": 0.5929,
      "step": 190
    },
    {
      "epoch": 0.14214641080312723,
      "grad_norm": 1.3646469116210938,
      "learning_rate": 2.375296912114014e-05,
      "loss": 0.5572,
      "step": 200
    },
    {
      "epoch": 0.14925373134328357,
      "grad_norm": 2.807896614074707,
      "learning_rate": 2.494061757719715e-05,
      "loss": 0.4975,
      "step": 210
    },
    {
      "epoch": 0.15636105188343993,
      "grad_norm": 3.3489198684692383,
      "learning_rate": 2.6128266033254157e-05,
      "loss": 0.4624,
      "step": 220
    },
    {
      "epoch": 0.1634683724235963,
      "grad_norm": 5.487392425537109,
      "learning_rate": 2.7315914489311166e-05,
      "loss": 0.3855,
      "step": 230
    },
    {
      "epoch": 0.17057569296375266,
      "grad_norm": 5.254972457885742,
      "learning_rate": 2.8503562945368172e-05,
      "loss": 0.3734,
      "step": 240
    },
    {
      "epoch": 0.17768301350390903,
      "grad_norm": 1.8933240175247192,
      "learning_rate": 2.9691211401425178e-05,
      "loss": 0.3944,
      "step": 250
    },
    {
      "epoch": 0.1847903340440654,
      "grad_norm": 4.456177234649658,
      "learning_rate": 3.0878859857482184e-05,
      "loss": 0.4172,
      "step": 260
    },
    {
      "epoch": 0.19189765458422176,
      "grad_norm": 1.598341703414917,
      "learning_rate": 3.20665083135392e-05,
      "loss": 0.3853,
      "step": 270
    },
    {
      "epoch": 0.19900497512437812,
      "grad_norm": 6.257580757141113,
      "learning_rate": 3.32541567695962e-05,
      "loss": 0.3628,
      "step": 280
    },
    {
      "epoch": 0.20611229566453448,
      "grad_norm": 2.7718470096588135,
      "learning_rate": 3.444180522565321e-05,
      "loss": 0.3328,
      "step": 290
    },
    {
      "epoch": 0.21321961620469082,
      "grad_norm": 4.024362564086914,
      "learning_rate": 3.5629453681710215e-05,
      "loss": 0.3519,
      "step": 300
    },
    {
      "epoch": 0.22032693674484718,
      "grad_norm": 4.726733684539795,
      "learning_rate": 3.681710213776722e-05,
      "loss": 0.2453,
      "step": 310
    },
    {
      "epoch": 0.22743425728500355,
      "grad_norm": 4.899835586547852,
      "learning_rate": 3.800475059382423e-05,
      "loss": 0.3468,
      "step": 320
    },
    {
      "epoch": 0.2345415778251599,
      "grad_norm": 2.7217540740966797,
      "learning_rate": 3.919239904988123e-05,
      "loss": 0.3005,
      "step": 330
    },
    {
      "epoch": 0.24164889836531628,
      "grad_norm": 6.257454872131348,
      "learning_rate": 4.0380047505938246e-05,
      "loss": 0.3682,
      "step": 340
    },
    {
      "epoch": 0.24875621890547264,
      "grad_norm": 2.2090303897857666,
      "learning_rate": 4.156769596199525e-05,
      "loss": 0.3873,
      "step": 350
    },
    {
      "epoch": 0.255863539445629,
      "grad_norm": 5.390707969665527,
      "learning_rate": 4.275534441805226e-05,
      "loss": 0.3325,
      "step": 360
    },
    {
      "epoch": 0.26297085998578534,
      "grad_norm": 2.519174337387085,
      "learning_rate": 4.394299287410927e-05,
      "loss": 0.2987,
      "step": 370
    },
    {
      "epoch": 0.27007818052594174,
      "grad_norm": 2.501490831375122,
      "learning_rate": 4.513064133016627e-05,
      "loss": 0.2898,
      "step": 380
    },
    {
      "epoch": 0.2771855010660981,
      "grad_norm": 2.2056262493133545,
      "learning_rate": 4.6318289786223276e-05,
      "loss": 0.3433,
      "step": 390
    },
    {
      "epoch": 0.28429282160625446,
      "grad_norm": 6.923454761505127,
      "learning_rate": 4.750593824228028e-05,
      "loss": 0.3164,
      "step": 400
    },
    {
      "epoch": 0.2914001421464108,
      "grad_norm": 9.64022159576416,
      "learning_rate": 4.8693586698337295e-05,
      "loss": 0.3755,
      "step": 410
    },
    {
      "epoch": 0.29850746268656714,
      "grad_norm": 4.991449356079102,
      "learning_rate": 4.98812351543943e-05,
      "loss": 0.2796,
      "step": 420
    },
    {
      "epoch": 0.30561478322672353,
      "grad_norm": 5.998867034912109,
      "learning_rate": 4.9881578947368425e-05,
      "loss": 0.3715,
      "step": 430
    },
    {
      "epoch": 0.31272210376687987,
      "grad_norm": 5.667739391326904,
      "learning_rate": 4.975e-05,
      "loss": 0.2542,
      "step": 440
    },
    {
      "epoch": 0.31982942430703626,
      "grad_norm": 5.550570487976074,
      "learning_rate": 4.961842105263158e-05,
      "loss": 0.3904,
      "step": 450
    },
    {
      "epoch": 0.3269367448471926,
      "grad_norm": 8.117775917053223,
      "learning_rate": 4.948684210526316e-05,
      "loss": 0.2519,
      "step": 460
    },
    {
      "epoch": 0.334044065387349,
      "grad_norm": 7.843630790710449,
      "learning_rate": 4.935526315789474e-05,
      "loss": 0.3189,
      "step": 470
    },
    {
      "epoch": 0.3411513859275053,
      "grad_norm": 2.288923978805542,
      "learning_rate": 4.9223684210526316e-05,
      "loss": 0.3157,
      "step": 480
    },
    {
      "epoch": 0.3482587064676617,
      "grad_norm": 1.9325124025344849,
      "learning_rate": 4.9092105263157894e-05,
      "loss": 0.3706,
      "step": 490
    },
    {
      "epoch": 0.35536602700781805,
      "grad_norm": 2.674156904220581,
      "learning_rate": 4.896052631578947e-05,
      "loss": 0.319,
      "step": 500
    },
    {
      "epoch": 0.3624733475479744,
      "grad_norm": 5.045976161956787,
      "learning_rate": 4.882894736842106e-05,
      "loss": 0.3339,
      "step": 510
    },
    {
      "epoch": 0.3695806680881308,
      "grad_norm": 3.9472484588623047,
      "learning_rate": 4.8697368421052636e-05,
      "loss": 0.2163,
      "step": 520
    },
    {
      "epoch": 0.3766879886282871,
      "grad_norm": 5.394717693328857,
      "learning_rate": 4.8565789473684214e-05,
      "loss": 0.4175,
      "step": 530
    },
    {
      "epoch": 0.3837953091684435,
      "grad_norm": 6.262406349182129,
      "learning_rate": 4.843421052631579e-05,
      "loss": 0.3121,
      "step": 540
    },
    {
      "epoch": 0.39090262970859985,
      "grad_norm": 6.164360046386719,
      "learning_rate": 4.830263157894737e-05,
      "loss": 0.3249,
      "step": 550
    },
    {
      "epoch": 0.39800995024875624,
      "grad_norm": 9.718866348266602,
      "learning_rate": 4.817105263157895e-05,
      "loss": 0.3576,
      "step": 560
    },
    {
      "epoch": 0.4051172707889126,
      "grad_norm": 5.971670150756836,
      "learning_rate": 4.803947368421053e-05,
      "loss": 0.3226,
      "step": 570
    },
    {
      "epoch": 0.41222459132906897,
      "grad_norm": 3.1125705242156982,
      "learning_rate": 4.7907894736842105e-05,
      "loss": 0.2725,
      "step": 580
    },
    {
      "epoch": 0.4193319118692253,
      "grad_norm": 4.04184627532959,
      "learning_rate": 4.7776315789473684e-05,
      "loss": 0.3089,
      "step": 590
    },
    {
      "epoch": 0.42643923240938164,
      "grad_norm": 2.561224937438965,
      "learning_rate": 4.764473684210526e-05,
      "loss": 0.325,
      "step": 600
    },
    {
      "epoch": 0.43354655294953803,
      "grad_norm": 3.3261706829071045,
      "learning_rate": 4.751315789473684e-05,
      "loss": 0.3446,
      "step": 610
    },
    {
      "epoch": 0.44065387348969437,
      "grad_norm": 3.924152135848999,
      "learning_rate": 4.738157894736842e-05,
      "loss": 0.2807,
      "step": 620
    },
    {
      "epoch": 0.44776119402985076,
      "grad_norm": 2.23335862159729,
      "learning_rate": 4.7249999999999997e-05,
      "loss": 0.3059,
      "step": 630
    },
    {
      "epoch": 0.4548685145700071,
      "grad_norm": 4.182961940765381,
      "learning_rate": 4.711842105263158e-05,
      "loss": 0.3992,
      "step": 640
    },
    {
      "epoch": 0.4619758351101635,
      "grad_norm": 4.688613414764404,
      "learning_rate": 4.698684210526316e-05,
      "loss": 0.3134,
      "step": 650
    },
    {
      "epoch": 0.4690831556503198,
      "grad_norm": 1.8492405414581299,
      "learning_rate": 4.685526315789474e-05,
      "loss": 0.2193,
      "step": 660
    },
    {
      "epoch": 0.47619047619047616,
      "grad_norm": 5.0105390548706055,
      "learning_rate": 4.6723684210526316e-05,
      "loss": 0.2758,
      "step": 670
    },
    {
      "epoch": 0.48329779673063256,
      "grad_norm": 6.5723958015441895,
      "learning_rate": 4.65921052631579e-05,
      "loss": 0.2321,
      "step": 680
    },
    {
      "epoch": 0.4904051172707889,
      "grad_norm": 7.94719934463501,
      "learning_rate": 4.646052631578948e-05,
      "loss": 0.3193,
      "step": 690
    },
    {
      "epoch": 0.4975124378109453,
      "grad_norm": 3.951179027557373,
      "learning_rate": 4.632894736842106e-05,
      "loss": 0.2433,
      "step": 700
    },
    {
      "epoch": 0.5046197583511016,
      "grad_norm": 4.8463311195373535,
      "learning_rate": 4.6197368421052636e-05,
      "loss": 0.2689,
      "step": 710
    },
    {
      "epoch": 0.511727078891258,
      "grad_norm": 3.1561691761016846,
      "learning_rate": 4.6065789473684214e-05,
      "loss": 0.3222,
      "step": 720
    },
    {
      "epoch": 0.5188343994314144,
      "grad_norm": 1.0864384174346924,
      "learning_rate": 4.593421052631579e-05,
      "loss": 0.1907,
      "step": 730
    },
    {
      "epoch": 0.5259417199715707,
      "grad_norm": 1.330297589302063,
      "learning_rate": 4.580263157894737e-05,
      "loss": 0.2139,
      "step": 740
    },
    {
      "epoch": 0.5330490405117271,
      "grad_norm": 1.2673184871673584,
      "learning_rate": 4.567105263157895e-05,
      "loss": 0.2246,
      "step": 750
    },
    {
      "epoch": 0.5401563610518835,
      "grad_norm": 3.660353422164917,
      "learning_rate": 4.553947368421053e-05,
      "loss": 0.333,
      "step": 760
    },
    {
      "epoch": 0.5472636815920398,
      "grad_norm": 1.6236813068389893,
      "learning_rate": 4.5407894736842106e-05,
      "loss": 0.3047,
      "step": 770
    },
    {
      "epoch": 0.5543710021321961,
      "grad_norm": 0.733258068561554,
      "learning_rate": 4.527631578947369e-05,
      "loss": 0.2031,
      "step": 780
    },
    {
      "epoch": 0.5614783226723525,
      "grad_norm": 6.871444225311279,
      "learning_rate": 4.514473684210527e-05,
      "loss": 0.3327,
      "step": 790
    },
    {
      "epoch": 0.5685856432125089,
      "grad_norm": 1.8644025325775146,
      "learning_rate": 4.501315789473685e-05,
      "loss": 0.3295,
      "step": 800
    },
    {
      "epoch": 0.5756929637526652,
      "grad_norm": 6.76733922958374,
      "learning_rate": 4.4881578947368425e-05,
      "loss": 0.347,
      "step": 810
    },
    {
      "epoch": 0.5828002842928216,
      "grad_norm": 3.8209919929504395,
      "learning_rate": 4.4750000000000004e-05,
      "loss": 0.3084,
      "step": 820
    },
    {
      "epoch": 0.589907604832978,
      "grad_norm": 2.0486080646514893,
      "learning_rate": 4.461842105263158e-05,
      "loss": 0.2658,
      "step": 830
    },
    {
      "epoch": 0.5970149253731343,
      "grad_norm": 8.4255952835083,
      "learning_rate": 4.448684210526316e-05,
      "loss": 0.2712,
      "step": 840
    },
    {
      "epoch": 0.6041222459132907,
      "grad_norm": 1.9007000923156738,
      "learning_rate": 4.435526315789474e-05,
      "loss": 0.2458,
      "step": 850
    },
    {
      "epoch": 0.6112295664534471,
      "grad_norm": 1.6504321098327637,
      "learning_rate": 4.4223684210526317e-05,
      "loss": 0.1856,
      "step": 860
    },
    {
      "epoch": 0.6183368869936035,
      "grad_norm": 3.5537304878234863,
      "learning_rate": 4.4092105263157895e-05,
      "loss": 0.3476,
      "step": 870
    },
    {
      "epoch": 0.6254442075337597,
      "grad_norm": 1.9437413215637207,
      "learning_rate": 4.396052631578947e-05,
      "loss": 0.3434,
      "step": 880
    },
    {
      "epoch": 0.6325515280739161,
      "grad_norm": 6.343731880187988,
      "learning_rate": 4.382894736842105e-05,
      "loss": 0.3709,
      "step": 890
    },
    {
      "epoch": 0.6396588486140725,
      "grad_norm": 1.0885382890701294,
      "learning_rate": 4.369736842105263e-05,
      "loss": 0.2641,
      "step": 900
    },
    {
      "epoch": 0.6467661691542289,
      "grad_norm": 3.1310012340545654,
      "learning_rate": 4.3565789473684215e-05,
      "loss": 0.2879,
      "step": 910
    },
    {
      "epoch": 0.6538734896943852,
      "grad_norm": 2.6443569660186768,
      "learning_rate": 4.343421052631579e-05,
      "loss": 0.2871,
      "step": 920
    },
    {
      "epoch": 0.6609808102345416,
      "grad_norm": 1.290907621383667,
      "learning_rate": 4.330263157894737e-05,
      "loss": 0.2255,
      "step": 930
    },
    {
      "epoch": 0.668088130774698,
      "grad_norm": 4.207393646240234,
      "learning_rate": 4.317105263157895e-05,
      "loss": 0.3429,
      "step": 940
    },
    {
      "epoch": 0.6751954513148543,
      "grad_norm": 2.4924087524414062,
      "learning_rate": 4.303947368421053e-05,
      "loss": 0.2385,
      "step": 950
    },
    {
      "epoch": 0.6823027718550106,
      "grad_norm": 2.008599042892456,
      "learning_rate": 4.2907894736842106e-05,
      "loss": 0.2812,
      "step": 960
    },
    {
      "epoch": 0.689410092395167,
      "grad_norm": 3.8274593353271484,
      "learning_rate": 4.2776315789473684e-05,
      "loss": 0.3223,
      "step": 970
    },
    {
      "epoch": 0.6965174129353234,
      "grad_norm": 1.7950327396392822,
      "learning_rate": 4.264473684210526e-05,
      "loss": 0.1991,
      "step": 980
    },
    {
      "epoch": 0.7036247334754797,
      "grad_norm": 10.735652923583984,
      "learning_rate": 4.251315789473684e-05,
      "loss": 0.2361,
      "step": 990
    },
    {
      "epoch": 0.7107320540156361,
      "grad_norm": 0.7412087321281433,
      "learning_rate": 4.2381578947368426e-05,
      "loss": 0.2064,
      "step": 1000
    },
    {
      "epoch": 0.7178393745557925,
      "grad_norm": 0.33822453022003174,
      "learning_rate": 4.2250000000000004e-05,
      "loss": 0.2571,
      "step": 1010
    },
    {
      "epoch": 0.7249466950959488,
      "grad_norm": 9.132181167602539,
      "learning_rate": 4.211842105263158e-05,
      "loss": 0.421,
      "step": 1020
    },
    {
      "epoch": 0.7320540156361052,
      "grad_norm": 2.2566213607788086,
      "learning_rate": 4.198684210526316e-05,
      "loss": 0.2296,
      "step": 1030
    },
    {
      "epoch": 0.7391613361762616,
      "grad_norm": 2.5582404136657715,
      "learning_rate": 4.185526315789474e-05,
      "loss": 0.3279,
      "step": 1040
    },
    {
      "epoch": 0.746268656716418,
      "grad_norm": 2.088041067123413,
      "learning_rate": 4.1723684210526324e-05,
      "loss": 0.2284,
      "step": 1050
    },
    {
      "epoch": 0.7533759772565742,
      "grad_norm": 3.8046681880950928,
      "learning_rate": 4.15921052631579e-05,
      "loss": 0.2638,
      "step": 1060
    },
    {
      "epoch": 0.7604832977967306,
      "grad_norm": 1.6764944791793823,
      "learning_rate": 4.146052631578948e-05,
      "loss": 0.229,
      "step": 1070
    },
    {
      "epoch": 0.767590618336887,
      "grad_norm": 1.4182195663452148,
      "learning_rate": 4.132894736842106e-05,
      "loss": 0.2927,
      "step": 1080
    },
    {
      "epoch": 0.7746979388770433,
      "grad_norm": 2.1676807403564453,
      "learning_rate": 4.1197368421052636e-05,
      "loss": 0.1989,
      "step": 1090
    },
    {
      "epoch": 0.7818052594171997,
      "grad_norm": 7.187459468841553,
      "learning_rate": 4.1065789473684215e-05,
      "loss": 0.3146,
      "step": 1100
    },
    {
      "epoch": 0.7889125799573561,
      "grad_norm": 4.405439376831055,
      "learning_rate": 4.093421052631579e-05,
      "loss": 0.2824,
      "step": 1110
    },
    {
      "epoch": 0.7960199004975125,
      "grad_norm": 9.812396049499512,
      "learning_rate": 4.080263157894737e-05,
      "loss": 0.3045,
      "step": 1120
    },
    {
      "epoch": 0.8031272210376688,
      "grad_norm": 2.0270044803619385,
      "learning_rate": 4.067105263157895e-05,
      "loss": 0.2199,
      "step": 1130
    },
    {
      "epoch": 0.8102345415778252,
      "grad_norm": 3.854360580444336,
      "learning_rate": 4.053947368421053e-05,
      "loss": 0.2942,
      "step": 1140
    },
    {
      "epoch": 0.8173418621179815,
      "grad_norm": 2.1559250354766846,
      "learning_rate": 4.0407894736842106e-05,
      "loss": 0.2663,
      "step": 1150
    },
    {
      "epoch": 0.8244491826581379,
      "grad_norm": 3.538825273513794,
      "learning_rate": 4.0276315789473684e-05,
      "loss": 0.2786,
      "step": 1160
    },
    {
      "epoch": 0.8315565031982942,
      "grad_norm": 2.7436070442199707,
      "learning_rate": 4.014473684210526e-05,
      "loss": 0.2341,
      "step": 1170
    },
    {
      "epoch": 0.8386638237384506,
      "grad_norm": 3.6034693717956543,
      "learning_rate": 4.001315789473684e-05,
      "loss": 0.167,
      "step": 1180
    },
    {
      "epoch": 0.845771144278607,
      "grad_norm": 1.6641169786453247,
      "learning_rate": 3.9881578947368426e-05,
      "loss": 0.2372,
      "step": 1190
    },
    {
      "epoch": 0.8528784648187633,
      "grad_norm": 8.15063190460205,
      "learning_rate": 3.9750000000000004e-05,
      "loss": 0.4378,
      "step": 1200
    },
    {
      "epoch": 0.8599857853589197,
      "grad_norm": 1.3333150148391724,
      "learning_rate": 3.961842105263158e-05,
      "loss": 0.244,
      "step": 1210
    },
    {
      "epoch": 0.8670931058990761,
      "grad_norm": 2.7276203632354736,
      "learning_rate": 3.948684210526316e-05,
      "loss": 0.254,
      "step": 1220
    },
    {
      "epoch": 0.8742004264392325,
      "grad_norm": 4.079287528991699,
      "learning_rate": 3.935526315789474e-05,
      "loss": 0.2366,
      "step": 1230
    },
    {
      "epoch": 0.8813077469793887,
      "grad_norm": 2.838575601577759,
      "learning_rate": 3.922368421052632e-05,
      "loss": 0.2379,
      "step": 1240
    },
    {
      "epoch": 0.8884150675195451,
      "grad_norm": 1.3774826526641846,
      "learning_rate": 3.9092105263157895e-05,
      "loss": 0.2413,
      "step": 1250
    },
    {
      "epoch": 0.8955223880597015,
      "grad_norm": 1.1256725788116455,
      "learning_rate": 3.8960526315789473e-05,
      "loss": 0.2206,
      "step": 1260
    },
    {
      "epoch": 0.9026297085998578,
      "grad_norm": 5.647760391235352,
      "learning_rate": 3.882894736842105e-05,
      "loss": 0.3458,
      "step": 1270
    },
    {
      "epoch": 0.9097370291400142,
      "grad_norm": 2.3039329051971436,
      "learning_rate": 3.869736842105263e-05,
      "loss": 0.3205,
      "step": 1280
    },
    {
      "epoch": 0.9168443496801706,
      "grad_norm": 4.309289932250977,
      "learning_rate": 3.856578947368421e-05,
      "loss": 0.2834,
      "step": 1290
    },
    {
      "epoch": 0.923951670220327,
      "grad_norm": 3.118396282196045,
      "learning_rate": 3.8434210526315786e-05,
      "loss": 0.3476,
      "step": 1300
    },
    {
      "epoch": 0.9310589907604833,
      "grad_norm": 4.317744731903076,
      "learning_rate": 3.8302631578947365e-05,
      "loss": 0.3108,
      "step": 1310
    },
    {
      "epoch": 0.9381663113006397,
      "grad_norm": 3.824692726135254,
      "learning_rate": 3.817105263157895e-05,
      "loss": 0.2096,
      "step": 1320
    },
    {
      "epoch": 0.945273631840796,
      "grad_norm": 4.6562180519104,
      "learning_rate": 3.803947368421053e-05,
      "loss": 0.2047,
      "step": 1330
    },
    {
      "epoch": 0.9523809523809523,
      "grad_norm": 1.304869532585144,
      "learning_rate": 3.7907894736842106e-05,
      "loss": 0.2882,
      "step": 1340
    },
    {
      "epoch": 0.9594882729211087,
      "grad_norm": 4.33357048034668,
      "learning_rate": 3.7776315789473684e-05,
      "loss": 0.3279,
      "step": 1350
    },
    {
      "epoch": 0.9665955934612651,
      "grad_norm": 1.6882264614105225,
      "learning_rate": 3.764473684210526e-05,
      "loss": 0.2399,
      "step": 1360
    },
    {
      "epoch": 0.9737029140014215,
      "grad_norm": 5.81782865524292,
      "learning_rate": 3.751315789473685e-05,
      "loss": 0.2859,
      "step": 1370
    },
    {
      "epoch": 0.9808102345415778,
      "grad_norm": 3.4679417610168457,
      "learning_rate": 3.7381578947368426e-05,
      "loss": 0.3001,
      "step": 1380
    },
    {
      "epoch": 0.9879175550817342,
      "grad_norm": 2.9034414291381836,
      "learning_rate": 3.7250000000000004e-05,
      "loss": 0.3453,
      "step": 1390
    },
    {
      "epoch": 0.9950248756218906,
      "grad_norm": 2.6851634979248047,
      "learning_rate": 3.711842105263158e-05,
      "loss": 0.2579,
      "step": 1400
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.89,
      "eval_f1": 0.8925361469323955,
      "eval_loss": 0.25772756338119507,
      "eval_precision": 0.8724216959511077,
      "eval_recall": 0.9136,
      "eval_runtime": 26.2764,
      "eval_samples_per_second": 95.142,
      "eval_steps_per_second": 5.975,
      "step": 1407
    },
    {
      "epoch": 1.0021321961620469,
      "grad_norm": 3.793579578399658,
      "learning_rate": 3.698684210526316e-05,
      "loss": 0.2216,
      "step": 1410
    },
    {
      "epoch": 1.0092395167022032,
      "grad_norm": 4.3174543380737305,
      "learning_rate": 3.685526315789474e-05,
      "loss": 0.2163,
      "step": 1420
    },
    {
      "epoch": 1.0163468372423596,
      "grad_norm": 3.404479503631592,
      "learning_rate": 3.672368421052632e-05,
      "loss": 0.2192,
      "step": 1430
    },
    {
      "epoch": 1.023454157782516,
      "grad_norm": 0.657733142375946,
      "learning_rate": 3.6592105263157895e-05,
      "loss": 0.2065,
      "step": 1440
    },
    {
      "epoch": 1.0305614783226724,
      "grad_norm": 3.703303098678589,
      "learning_rate": 3.6460526315789474e-05,
      "loss": 0.3295,
      "step": 1450
    },
    {
      "epoch": 1.0376687988628288,
      "grad_norm": 7.082793235778809,
      "learning_rate": 3.632894736842106e-05,
      "loss": 0.2282,
      "step": 1460
    },
    {
      "epoch": 1.044776119402985,
      "grad_norm": 1.5929033756256104,
      "learning_rate": 3.619736842105264e-05,
      "loss": 0.2657,
      "step": 1470
    },
    {
      "epoch": 1.0518834399431414,
      "grad_norm": 3.138312339782715,
      "learning_rate": 3.6065789473684215e-05,
      "loss": 0.2359,
      "step": 1480
    },
    {
      "epoch": 1.0589907604832978,
      "grad_norm": 1.545058012008667,
      "learning_rate": 3.5934210526315793e-05,
      "loss": 0.2327,
      "step": 1490
    },
    {
      "epoch": 1.0660980810234542,
      "grad_norm": 1.2006055116653442,
      "learning_rate": 3.580263157894737e-05,
      "loss": 0.2877,
      "step": 1500
    },
    {
      "epoch": 1.0732054015636106,
      "grad_norm": 7.101900577545166,
      "learning_rate": 3.567105263157895e-05,
      "loss": 0.2044,
      "step": 1510
    },
    {
      "epoch": 1.080312722103767,
      "grad_norm": 3.694319486618042,
      "learning_rate": 3.553947368421053e-05,
      "loss": 0.3193,
      "step": 1520
    },
    {
      "epoch": 1.0874200426439233,
      "grad_norm": 4.273890018463135,
      "learning_rate": 3.5407894736842106e-05,
      "loss": 0.3226,
      "step": 1530
    },
    {
      "epoch": 1.0945273631840795,
      "grad_norm": 1.5978341102600098,
      "learning_rate": 3.5276315789473685e-05,
      "loss": 0.226,
      "step": 1540
    },
    {
      "epoch": 1.101634683724236,
      "grad_norm": 3.4300689697265625,
      "learning_rate": 3.514473684210526e-05,
      "loss": 0.3363,
      "step": 1550
    },
    {
      "epoch": 1.1087420042643923,
      "grad_norm": 7.741127967834473,
      "learning_rate": 3.501315789473684e-05,
      "loss": 0.2029,
      "step": 1560
    },
    {
      "epoch": 1.1158493248045487,
      "grad_norm": 4.822306156158447,
      "learning_rate": 3.488157894736842e-05,
      "loss": 0.2253,
      "step": 1570
    },
    {
      "epoch": 1.122956645344705,
      "grad_norm": 2.4434854984283447,
      "learning_rate": 3.475e-05,
      "loss": 0.2886,
      "step": 1580
    },
    {
      "epoch": 1.1300639658848615,
      "grad_norm": 2.9445090293884277,
      "learning_rate": 3.461842105263158e-05,
      "loss": 0.1553,
      "step": 1590
    },
    {
      "epoch": 1.1371712864250179,
      "grad_norm": 1.0357704162597656,
      "learning_rate": 3.448684210526316e-05,
      "loss": 0.2762,
      "step": 1600
    },
    {
      "epoch": 1.144278606965174,
      "grad_norm": 4.330826759338379,
      "learning_rate": 3.435526315789474e-05,
      "loss": 0.1937,
      "step": 1610
    },
    {
      "epoch": 1.1513859275053304,
      "grad_norm": 2.3939201831817627,
      "learning_rate": 3.422368421052632e-05,
      "loss": 0.2321,
      "step": 1620
    },
    {
      "epoch": 1.1584932480454868,
      "grad_norm": 6.7557830810546875,
      "learning_rate": 3.4092105263157896e-05,
      "loss": 0.2478,
      "step": 1630
    },
    {
      "epoch": 1.1656005685856432,
      "grad_norm": 10.910487174987793,
      "learning_rate": 3.3960526315789474e-05,
      "loss": 0.2903,
      "step": 1640
    },
    {
      "epoch": 1.1727078891257996,
      "grad_norm": 6.098073482513428,
      "learning_rate": 3.382894736842105e-05,
      "loss": 0.2127,
      "step": 1650
    },
    {
      "epoch": 1.179815209665956,
      "grad_norm": 4.046130180358887,
      "learning_rate": 3.369736842105263e-05,
      "loss": 0.2538,
      "step": 1660
    },
    {
      "epoch": 1.1869225302061124,
      "grad_norm": 2.0741262435913086,
      "learning_rate": 3.356578947368421e-05,
      "loss": 0.1839,
      "step": 1670
    },
    {
      "epoch": 1.1940298507462686,
      "grad_norm": 2.536003828048706,
      "learning_rate": 3.343421052631579e-05,
      "loss": 0.2203,
      "step": 1680
    },
    {
      "epoch": 1.201137171286425,
      "grad_norm": 2.146042585372925,
      "learning_rate": 3.330263157894737e-05,
      "loss": 0.2183,
      "step": 1690
    },
    {
      "epoch": 1.2082444918265813,
      "grad_norm": 4.157567977905273,
      "learning_rate": 3.317105263157895e-05,
      "loss": 0.2512,
      "step": 1700
    },
    {
      "epoch": 1.2153518123667377,
      "grad_norm": 2.9470837116241455,
      "learning_rate": 3.303947368421053e-05,
      "loss": 0.3179,
      "step": 1710
    },
    {
      "epoch": 1.2224591329068941,
      "grad_norm": 3.6047775745391846,
      "learning_rate": 3.290789473684211e-05,
      "loss": 0.3446,
      "step": 1720
    },
    {
      "epoch": 1.2295664534470505,
      "grad_norm": 2.1411168575286865,
      "learning_rate": 3.277631578947369e-05,
      "loss": 0.2182,
      "step": 1730
    },
    {
      "epoch": 1.236673773987207,
      "grad_norm": 3.097111463546753,
      "learning_rate": 3.264473684210527e-05,
      "loss": 0.2691,
      "step": 1740
    },
    {
      "epoch": 1.243781094527363,
      "grad_norm": 0.6328858137130737,
      "learning_rate": 3.251315789473685e-05,
      "loss": 0.2689,
      "step": 1750
    },
    {
      "epoch": 1.2508884150675195,
      "grad_norm": 1.7755683660507202,
      "learning_rate": 3.2381578947368426e-05,
      "loss": 0.2424,
      "step": 1760
    },
    {
      "epoch": 1.2579957356076759,
      "grad_norm": 1.9455580711364746,
      "learning_rate": 3.2250000000000005e-05,
      "loss": 0.323,
      "step": 1770
    },
    {
      "epoch": 1.2651030561478323,
      "grad_norm": 4.141851425170898,
      "learning_rate": 3.211842105263158e-05,
      "loss": 0.2563,
      "step": 1780
    },
    {
      "epoch": 1.2722103766879886,
      "grad_norm": 3.1684410572052,
      "learning_rate": 3.198684210526316e-05,
      "loss": 0.2308,
      "step": 1790
    },
    {
      "epoch": 1.279317697228145,
      "grad_norm": 1.7720035314559937,
      "learning_rate": 3.185526315789474e-05,
      "loss": 0.2011,
      "step": 1800
    },
    {
      "epoch": 1.2864250177683014,
      "grad_norm": 2.589958667755127,
      "learning_rate": 3.172368421052632e-05,
      "loss": 0.2662,
      "step": 1810
    },
    {
      "epoch": 1.2935323383084576,
      "grad_norm": 2.5457613468170166,
      "learning_rate": 3.1592105263157896e-05,
      "loss": 0.2612,
      "step": 1820
    },
    {
      "epoch": 1.3006396588486142,
      "grad_norm": 5.333953857421875,
      "learning_rate": 3.1460526315789474e-05,
      "loss": 0.1807,
      "step": 1830
    },
    {
      "epoch": 1.3077469793887704,
      "grad_norm": 3.2483415603637695,
      "learning_rate": 3.132894736842105e-05,
      "loss": 0.2285,
      "step": 1840
    },
    {
      "epoch": 1.3148542999289268,
      "grad_norm": 4.560727596282959,
      "learning_rate": 3.119736842105263e-05,
      "loss": 0.2511,
      "step": 1850
    },
    {
      "epoch": 1.3219616204690832,
      "grad_norm": 7.185634136199951,
      "learning_rate": 3.1065789473684216e-05,
      "loss": 0.2675,
      "step": 1860
    },
    {
      "epoch": 1.3290689410092396,
      "grad_norm": 3.519988775253296,
      "learning_rate": 3.0934210526315794e-05,
      "loss": 0.2268,
      "step": 1870
    },
    {
      "epoch": 1.336176261549396,
      "grad_norm": 3.734890937805176,
      "learning_rate": 3.080263157894737e-05,
      "loss": 0.2893,
      "step": 1880
    },
    {
      "epoch": 1.3432835820895521,
      "grad_norm": 5.669505596160889,
      "learning_rate": 3.067105263157895e-05,
      "loss": 0.3075,
      "step": 1890
    },
    {
      "epoch": 1.3503909026297087,
      "grad_norm": 4.109992027282715,
      "learning_rate": 3.053947368421053e-05,
      "loss": 0.2155,
      "step": 1900
    },
    {
      "epoch": 1.357498223169865,
      "grad_norm": 2.9438469409942627,
      "learning_rate": 3.0407894736842107e-05,
      "loss": 0.3198,
      "step": 1910
    },
    {
      "epoch": 1.3646055437100213,
      "grad_norm": 3.634521722793579,
      "learning_rate": 3.0276315789473685e-05,
      "loss": 0.2442,
      "step": 1920
    },
    {
      "epoch": 1.3717128642501777,
      "grad_norm": 2.9953436851501465,
      "learning_rate": 3.0144736842105263e-05,
      "loss": 0.2108,
      "step": 1930
    },
    {
      "epoch": 1.378820184790334,
      "grad_norm": 3.3080363273620605,
      "learning_rate": 3.001315789473684e-05,
      "loss": 0.1952,
      "step": 1940
    },
    {
      "epoch": 1.3859275053304905,
      "grad_norm": 5.806305408477783,
      "learning_rate": 2.9881578947368423e-05,
      "loss": 0.2693,
      "step": 1950
    },
    {
      "epoch": 1.3930348258706466,
      "grad_norm": 6.529880046844482,
      "learning_rate": 2.975e-05,
      "loss": 0.2171,
      "step": 1960
    },
    {
      "epoch": 1.4001421464108033,
      "grad_norm": 4.068181991577148,
      "learning_rate": 2.961842105263158e-05,
      "loss": 0.2956,
      "step": 1970
    },
    {
      "epoch": 1.4072494669509594,
      "grad_norm": 4.2109599113464355,
      "learning_rate": 2.9486842105263158e-05,
      "loss": 0.3284,
      "step": 1980
    },
    {
      "epoch": 1.4143567874911158,
      "grad_norm": 3.0381481647491455,
      "learning_rate": 2.9355263157894736e-05,
      "loss": 0.1549,
      "step": 1990
    },
    {
      "epoch": 1.4214641080312722,
      "grad_norm": 1.5666879415512085,
      "learning_rate": 2.922368421052632e-05,
      "loss": 0.2103,
      "step": 2000
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 3.5578951835632324,
      "learning_rate": 2.90921052631579e-05,
      "loss": 0.2652,
      "step": 2010
    },
    {
      "epoch": 1.435678749111585,
      "grad_norm": 2.7619407176971436,
      "learning_rate": 2.8960526315789478e-05,
      "loss": 0.1918,
      "step": 2020
    },
    {
      "epoch": 1.4427860696517412,
      "grad_norm": 2.652261972427368,
      "learning_rate": 2.8828947368421056e-05,
      "loss": 0.2345,
      "step": 2030
    },
    {
      "epoch": 1.4498933901918978,
      "grad_norm": 1.6996967792510986,
      "learning_rate": 2.8697368421052634e-05,
      "loss": 0.3417,
      "step": 2040
    },
    {
      "epoch": 1.457000710732054,
      "grad_norm": 3.178098440170288,
      "learning_rate": 2.8565789473684212e-05,
      "loss": 0.2301,
      "step": 2050
    },
    {
      "epoch": 1.4641080312722103,
      "grad_norm": 3.5727219581604004,
      "learning_rate": 2.843421052631579e-05,
      "loss": 0.2629,
      "step": 2060
    },
    {
      "epoch": 1.4712153518123667,
      "grad_norm": 2.322671890258789,
      "learning_rate": 2.830263157894737e-05,
      "loss": 0.1728,
      "step": 2070
    },
    {
      "epoch": 1.4783226723525231,
      "grad_norm": 4.909292221069336,
      "learning_rate": 2.8171052631578947e-05,
      "loss": 0.417,
      "step": 2080
    },
    {
      "epoch": 1.4854299928926795,
      "grad_norm": 5.114230632781982,
      "learning_rate": 2.8039473684210525e-05,
      "loss": 0.2574,
      "step": 2090
    },
    {
      "epoch": 1.4925373134328357,
      "grad_norm": 3.8492746353149414,
      "learning_rate": 2.7907894736842104e-05,
      "loss": 0.1799,
      "step": 2100
    },
    {
      "epoch": 1.4996446339729923,
      "grad_norm": 3.2957308292388916,
      "learning_rate": 2.7776315789473685e-05,
      "loss": 0.1456,
      "step": 2110
    },
    {
      "epoch": 1.5067519545131485,
      "grad_norm": 4.799927711486816,
      "learning_rate": 2.7644736842105264e-05,
      "loss": 0.2494,
      "step": 2120
    },
    {
      "epoch": 1.5138592750533049,
      "grad_norm": 0.9411325454711914,
      "learning_rate": 2.7513157894736842e-05,
      "loss": 0.2646,
      "step": 2130
    },
    {
      "epoch": 1.5209665955934613,
      "grad_norm": 5.631038188934326,
      "learning_rate": 2.7381578947368423e-05,
      "loss": 0.1745,
      "step": 2140
    },
    {
      "epoch": 1.5280739161336176,
      "grad_norm": 2.2165844440460205,
      "learning_rate": 2.725e-05,
      "loss": 0.222,
      "step": 2150
    },
    {
      "epoch": 1.535181236673774,
      "grad_norm": 4.229945182800293,
      "learning_rate": 2.7118421052631583e-05,
      "loss": 0.3043,
      "step": 2160
    },
    {
      "epoch": 1.5422885572139302,
      "grad_norm": 3.448711633682251,
      "learning_rate": 2.698684210526316e-05,
      "loss": 0.2165,
      "step": 2170
    },
    {
      "epoch": 1.5493958777540868,
      "grad_norm": 4.016654968261719,
      "learning_rate": 2.685526315789474e-05,
      "loss": 0.2246,
      "step": 2180
    },
    {
      "epoch": 1.556503198294243,
      "grad_norm": 3.1339986324310303,
      "learning_rate": 2.6723684210526318e-05,
      "loss": 0.2391,
      "step": 2190
    },
    {
      "epoch": 1.5636105188343994,
      "grad_norm": 2.353510618209839,
      "learning_rate": 2.6592105263157896e-05,
      "loss": 0.3354,
      "step": 2200
    },
    {
      "epoch": 1.5707178393745558,
      "grad_norm": 3.5594868659973145,
      "learning_rate": 2.6460526315789475e-05,
      "loss": 0.2062,
      "step": 2210
    },
    {
      "epoch": 1.5778251599147122,
      "grad_norm": 5.032797813415527,
      "learning_rate": 2.6328947368421053e-05,
      "loss": 0.2496,
      "step": 2220
    },
    {
      "epoch": 1.5849324804548686,
      "grad_norm": 0.8426063656806946,
      "learning_rate": 2.619736842105263e-05,
      "loss": 0.1912,
      "step": 2230
    },
    {
      "epoch": 1.5920398009950247,
      "grad_norm": 1.1189887523651123,
      "learning_rate": 2.606578947368421e-05,
      "loss": 0.2263,
      "step": 2240
    },
    {
      "epoch": 1.5991471215351813,
      "grad_norm": 6.07562780380249,
      "learning_rate": 2.5934210526315788e-05,
      "loss": 0.2654,
      "step": 2250
    },
    {
      "epoch": 1.6062544420753375,
      "grad_norm": 4.527456283569336,
      "learning_rate": 2.5802631578947366e-05,
      "loss": 0.207,
      "step": 2260
    },
    {
      "epoch": 1.613361762615494,
      "grad_norm": 2.1448047161102295,
      "learning_rate": 2.567105263157895e-05,
      "loss": 0.1378,
      "step": 2270
    },
    {
      "epoch": 1.6204690831556503,
      "grad_norm": 2.861673355102539,
      "learning_rate": 2.553947368421053e-05,
      "loss": 0.2529,
      "step": 2280
    },
    {
      "epoch": 1.6275764036958067,
      "grad_norm": 3.847318410873413,
      "learning_rate": 2.5407894736842107e-05,
      "loss": 0.2545,
      "step": 2290
    },
    {
      "epoch": 1.634683724235963,
      "grad_norm": 4.964937210083008,
      "learning_rate": 2.5276315789473686e-05,
      "loss": 0.1133,
      "step": 2300
    },
    {
      "epoch": 1.6417910447761193,
      "grad_norm": 3.343111991882324,
      "learning_rate": 2.5144736842105264e-05,
      "loss": 0.2731,
      "step": 2310
    },
    {
      "epoch": 1.6488983653162759,
      "grad_norm": 3.0687644481658936,
      "learning_rate": 2.5013157894736845e-05,
      "loss": 0.1793,
      "step": 2320
    },
    {
      "epoch": 1.656005685856432,
      "grad_norm": 7.275823593139648,
      "learning_rate": 2.4881578947368424e-05,
      "loss": 0.239,
      "step": 2330
    },
    {
      "epoch": 1.6631130063965884,
      "grad_norm": 0.2020268589258194,
      "learning_rate": 2.4750000000000002e-05,
      "loss": 0.2194,
      "step": 2340
    },
    {
      "epoch": 1.6702203269367448,
      "grad_norm": 0.7004907131195068,
      "learning_rate": 2.461842105263158e-05,
      "loss": 0.143,
      "step": 2350
    },
    {
      "epoch": 1.6773276474769012,
      "grad_norm": 6.858715534210205,
      "learning_rate": 2.448684210526316e-05,
      "loss": 0.2046,
      "step": 2360
    },
    {
      "epoch": 1.6844349680170576,
      "grad_norm": 2.3254053592681885,
      "learning_rate": 2.435526315789474e-05,
      "loss": 0.2665,
      "step": 2370
    },
    {
      "epoch": 1.6915422885572138,
      "grad_norm": 3.523761510848999,
      "learning_rate": 2.4223684210526318e-05,
      "loss": 0.135,
      "step": 2380
    },
    {
      "epoch": 1.6986496090973704,
      "grad_norm": 3.138049602508545,
      "learning_rate": 2.4092105263157897e-05,
      "loss": 0.3142,
      "step": 2390
    },
    {
      "epoch": 1.7057569296375266,
      "grad_norm": 3.7495601177215576,
      "learning_rate": 2.3960526315789475e-05,
      "loss": 0.2822,
      "step": 2400
    },
    {
      "epoch": 1.7128642501776832,
      "grad_norm": 3.083022117614746,
      "learning_rate": 2.3828947368421053e-05,
      "loss": 0.322,
      "step": 2410
    },
    {
      "epoch": 1.7199715707178393,
      "grad_norm": 6.77858829498291,
      "learning_rate": 2.369736842105263e-05,
      "loss": 0.2558,
      "step": 2420
    },
    {
      "epoch": 1.7270788912579957,
      "grad_norm": 2.77769136428833,
      "learning_rate": 2.356578947368421e-05,
      "loss": 0.2508,
      "step": 2430
    },
    {
      "epoch": 1.7341862117981521,
      "grad_norm": 1.867080807685852,
      "learning_rate": 2.343421052631579e-05,
      "loss": 0.2716,
      "step": 2440
    },
    {
      "epoch": 1.7412935323383083,
      "grad_norm": 2.077763557434082,
      "learning_rate": 2.330263157894737e-05,
      "loss": 0.2053,
      "step": 2450
    },
    {
      "epoch": 1.748400852878465,
      "grad_norm": 1.7868210077285767,
      "learning_rate": 2.3171052631578948e-05,
      "loss": 0.2404,
      "step": 2460
    },
    {
      "epoch": 1.755508173418621,
      "grad_norm": 4.219913959503174,
      "learning_rate": 2.3039473684210526e-05,
      "loss": 0.2702,
      "step": 2470
    },
    {
      "epoch": 1.7626154939587777,
      "grad_norm": 2.526441812515259,
      "learning_rate": 2.2907894736842108e-05,
      "loss": 0.2956,
      "step": 2480
    },
    {
      "epoch": 1.7697228144989339,
      "grad_norm": 3.2083938121795654,
      "learning_rate": 2.2776315789473686e-05,
      "loss": 0.243,
      "step": 2490
    },
    {
      "epoch": 1.7768301350390903,
      "grad_norm": 6.562258243560791,
      "learning_rate": 2.2644736842105264e-05,
      "loss": 0.2999,
      "step": 2500
    },
    {
      "epoch": 1.7839374555792467,
      "grad_norm": 0.8478699326515198,
      "learning_rate": 2.2513157894736846e-05,
      "loss": 0.2228,
      "step": 2510
    },
    {
      "epoch": 1.7910447761194028,
      "grad_norm": 7.054643154144287,
      "learning_rate": 2.2381578947368424e-05,
      "loss": 0.2277,
      "step": 2520
    },
    {
      "epoch": 1.7981520966595594,
      "grad_norm": 4.350286960601807,
      "learning_rate": 2.2250000000000002e-05,
      "loss": 0.2733,
      "step": 2530
    },
    {
      "epoch": 1.8052594171997156,
      "grad_norm": 2.7146639823913574,
      "learning_rate": 2.211842105263158e-05,
      "loss": 0.2293,
      "step": 2540
    },
    {
      "epoch": 1.8123667377398722,
      "grad_norm": 3.4001247882843018,
      "learning_rate": 2.198684210526316e-05,
      "loss": 0.229,
      "step": 2550
    },
    {
      "epoch": 1.8194740582800284,
      "grad_norm": 0.5263732671737671,
      "learning_rate": 2.1855263157894737e-05,
      "loss": 0.2116,
      "step": 2560
    },
    {
      "epoch": 1.8265813788201848,
      "grad_norm": 2.533806085586548,
      "learning_rate": 2.1723684210526315e-05,
      "loss": 0.3046,
      "step": 2570
    },
    {
      "epoch": 1.8336886993603412,
      "grad_norm": 5.011928558349609,
      "learning_rate": 2.1592105263157897e-05,
      "loss": 0.3171,
      "step": 2580
    },
    {
      "epoch": 1.8407960199004973,
      "grad_norm": 2.181133270263672,
      "learning_rate": 2.1460526315789475e-05,
      "loss": 0.2725,
      "step": 2590
    },
    {
      "epoch": 1.847903340440654,
      "grad_norm": 3.8776519298553467,
      "learning_rate": 2.1328947368421053e-05,
      "loss": 0.233,
      "step": 2600
    },
    {
      "epoch": 1.8550106609808101,
      "grad_norm": 5.385402679443359,
      "learning_rate": 2.119736842105263e-05,
      "loss": 0.2111,
      "step": 2610
    },
    {
      "epoch": 1.8621179815209667,
      "grad_norm": 0.7967531681060791,
      "learning_rate": 2.106578947368421e-05,
      "loss": 0.1463,
      "step": 2620
    },
    {
      "epoch": 1.869225302061123,
      "grad_norm": 5.762551307678223,
      "learning_rate": 2.0934210526315788e-05,
      "loss": 0.2408,
      "step": 2630
    },
    {
      "epoch": 1.8763326226012793,
      "grad_norm": 1.8894364833831787,
      "learning_rate": 2.080263157894737e-05,
      "loss": 0.3011,
      "step": 2640
    },
    {
      "epoch": 1.8834399431414357,
      "grad_norm": 2.0554144382476807,
      "learning_rate": 2.0671052631578948e-05,
      "loss": 0.2499,
      "step": 2650
    },
    {
      "epoch": 1.890547263681592,
      "grad_norm": 3.402318000793457,
      "learning_rate": 2.053947368421053e-05,
      "loss": 0.249,
      "step": 2660
    },
    {
      "epoch": 1.8976545842217485,
      "grad_norm": 4.904726982116699,
      "learning_rate": 2.0407894736842108e-05,
      "loss": 0.2136,
      "step": 2670
    },
    {
      "epoch": 1.9047619047619047,
      "grad_norm": 4.702792644500732,
      "learning_rate": 2.0276315789473686e-05,
      "loss": 0.1841,
      "step": 2680
    },
    {
      "epoch": 1.9118692253020613,
      "grad_norm": 2.029761791229248,
      "learning_rate": 2.0144736842105264e-05,
      "loss": 0.2484,
      "step": 2690
    },
    {
      "epoch": 1.9189765458422174,
      "grad_norm": 4.413347244262695,
      "learning_rate": 2.0013157894736842e-05,
      "loss": 0.3175,
      "step": 2700
    },
    {
      "epoch": 1.9260838663823738,
      "grad_norm": 3.3358731269836426,
      "learning_rate": 1.9881578947368424e-05,
      "loss": 0.2726,
      "step": 2710
    },
    {
      "epoch": 1.9331911869225302,
      "grad_norm": 1.5582445859909058,
      "learning_rate": 1.9750000000000002e-05,
      "loss": 0.1691,
      "step": 2720
    },
    {
      "epoch": 1.9402985074626866,
      "grad_norm": 2.6982264518737793,
      "learning_rate": 1.961842105263158e-05,
      "loss": 0.206,
      "step": 2730
    },
    {
      "epoch": 1.947405828002843,
      "grad_norm": 2.72930645942688,
      "learning_rate": 1.948684210526316e-05,
      "loss": 0.2283,
      "step": 2740
    },
    {
      "epoch": 1.9545131485429992,
      "grad_norm": 5.694418907165527,
      "learning_rate": 1.9355263157894737e-05,
      "loss": 0.2636,
      "step": 2750
    },
    {
      "epoch": 1.9616204690831558,
      "grad_norm": 6.433297157287598,
      "learning_rate": 1.9223684210526315e-05,
      "loss": 0.2334,
      "step": 2760
    },
    {
      "epoch": 1.968727789623312,
      "grad_norm": 7.017293930053711,
      "learning_rate": 1.9092105263157894e-05,
      "loss": 0.2404,
      "step": 2770
    },
    {
      "epoch": 1.9758351101634684,
      "grad_norm": 2.52168607711792,
      "learning_rate": 1.8960526315789475e-05,
      "loss": 0.2719,
      "step": 2780
    },
    {
      "epoch": 1.9829424307036247,
      "grad_norm": 7.672648906707764,
      "learning_rate": 1.8828947368421053e-05,
      "loss": 0.2256,
      "step": 2790
    },
    {
      "epoch": 1.9900497512437811,
      "grad_norm": 5.944643020629883,
      "learning_rate": 1.869736842105263e-05,
      "loss": 0.2772,
      "step": 2800
    },
    {
      "epoch": 1.9971570717839375,
      "grad_norm": 2.0278024673461914,
      "learning_rate": 1.856578947368421e-05,
      "loss": 0.2465,
      "step": 2810
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8976,
      "eval_f1": 0.9002338269680438,
      "eval_loss": 0.24928808212280273,
      "eval_precision": 0.8776595744680851,
      "eval_recall": 0.924,
      "eval_runtime": 26.3427,
      "eval_samples_per_second": 94.903,
      "eval_steps_per_second": 5.96,
      "step": 2814
    }
  ],
  "logging_steps": 10,
  "max_steps": 4221,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6165194895360000.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
