{
  "best_metric": 0.902,
  "best_model_checkpoint": "./results1/checkpoint-4221",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 4221,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007107320540156361,
      "grad_norm": 0.8181204199790955,
      "learning_rate": 1.187648456057007e-06,
      "loss": 0.7004,
      "step": 10
    },
    {
      "epoch": 0.014214641080312722,
      "grad_norm": 1.0279542207717896,
      "learning_rate": 2.375296912114014e-06,
      "loss": 0.6958,
      "step": 20
    },
    {
      "epoch": 0.021321961620469083,
      "grad_norm": 0.8940870761871338,
      "learning_rate": 3.5629453681710215e-06,
      "loss": 0.6875,
      "step": 30
    },
    {
      "epoch": 0.028429282160625444,
      "grad_norm": 0.857053279876709,
      "learning_rate": 4.750593824228028e-06,
      "loss": 0.6893,
      "step": 40
    },
    {
      "epoch": 0.03553660270078181,
      "grad_norm": 1.266706109046936,
      "learning_rate": 5.938242280285035e-06,
      "loss": 0.6863,
      "step": 50
    },
    {
      "epoch": 0.042643923240938165,
      "grad_norm": 0.9493836164474487,
      "learning_rate": 7.125890736342043e-06,
      "loss": 0.6844,
      "step": 60
    },
    {
      "epoch": 0.04975124378109453,
      "grad_norm": 0.9968581795692444,
      "learning_rate": 8.31353919239905e-06,
      "loss": 0.6927,
      "step": 70
    },
    {
      "epoch": 0.05685856432125089,
      "grad_norm": 0.7703754305839539,
      "learning_rate": 9.501187648456057e-06,
      "loss": 0.6892,
      "step": 80
    },
    {
      "epoch": 0.06396588486140725,
      "grad_norm": 1.190040111541748,
      "learning_rate": 1.0688836104513065e-05,
      "loss": 0.6839,
      "step": 90
    },
    {
      "epoch": 0.07107320540156362,
      "grad_norm": 1.089756965637207,
      "learning_rate": 1.187648456057007e-05,
      "loss": 0.6867,
      "step": 100
    },
    {
      "epoch": 0.07818052594171997,
      "grad_norm": 0.7433860898017883,
      "learning_rate": 1.3064133016627078e-05,
      "loss": 0.6729,
      "step": 110
    },
    {
      "epoch": 0.08528784648187633,
      "grad_norm": 0.9344238638877869,
      "learning_rate": 1.4251781472684086e-05,
      "loss": 0.6764,
      "step": 120
    },
    {
      "epoch": 0.0923951670220327,
      "grad_norm": 1.026196002960205,
      "learning_rate": 1.5439429928741092e-05,
      "loss": 0.6824,
      "step": 130
    },
    {
      "epoch": 0.09950248756218906,
      "grad_norm": 1.1045241355895996,
      "learning_rate": 1.66270783847981e-05,
      "loss": 0.6691,
      "step": 140
    },
    {
      "epoch": 0.10660980810234541,
      "grad_norm": 0.8705831170082092,
      "learning_rate": 1.7814726840855108e-05,
      "loss": 0.6713,
      "step": 150
    },
    {
      "epoch": 0.11371712864250177,
      "grad_norm": 1.0659359693527222,
      "learning_rate": 1.9002375296912114e-05,
      "loss": 0.6594,
      "step": 160
    },
    {
      "epoch": 0.12082444918265814,
      "grad_norm": 1.5173131227493286,
      "learning_rate": 2.0190023752969123e-05,
      "loss": 0.6474,
      "step": 170
    },
    {
      "epoch": 0.1279317697228145,
      "grad_norm": 2.0305075645446777,
      "learning_rate": 2.137767220902613e-05,
      "loss": 0.6248,
      "step": 180
    },
    {
      "epoch": 0.13503909026297087,
      "grad_norm": 1.3181008100509644,
      "learning_rate": 2.2565320665083135e-05,
      "loss": 0.5929,
      "step": 190
    },
    {
      "epoch": 0.14214641080312723,
      "grad_norm": 1.3646469116210938,
      "learning_rate": 2.375296912114014e-05,
      "loss": 0.5572,
      "step": 200
    },
    {
      "epoch": 0.14925373134328357,
      "grad_norm": 2.807896614074707,
      "learning_rate": 2.494061757719715e-05,
      "loss": 0.4975,
      "step": 210
    },
    {
      "epoch": 0.15636105188343993,
      "grad_norm": 3.3489198684692383,
      "learning_rate": 2.6128266033254157e-05,
      "loss": 0.4624,
      "step": 220
    },
    {
      "epoch": 0.1634683724235963,
      "grad_norm": 5.487392425537109,
      "learning_rate": 2.7315914489311166e-05,
      "loss": 0.3855,
      "step": 230
    },
    {
      "epoch": 0.17057569296375266,
      "grad_norm": 5.254972457885742,
      "learning_rate": 2.8503562945368172e-05,
      "loss": 0.3734,
      "step": 240
    },
    {
      "epoch": 0.17768301350390903,
      "grad_norm": 1.8933240175247192,
      "learning_rate": 2.9691211401425178e-05,
      "loss": 0.3944,
      "step": 250
    },
    {
      "epoch": 0.1847903340440654,
      "grad_norm": 4.456177234649658,
      "learning_rate": 3.0878859857482184e-05,
      "loss": 0.4172,
      "step": 260
    },
    {
      "epoch": 0.19189765458422176,
      "grad_norm": 1.598341703414917,
      "learning_rate": 3.20665083135392e-05,
      "loss": 0.3853,
      "step": 270
    },
    {
      "epoch": 0.19900497512437812,
      "grad_norm": 6.257580757141113,
      "learning_rate": 3.32541567695962e-05,
      "loss": 0.3628,
      "step": 280
    },
    {
      "epoch": 0.20611229566453448,
      "grad_norm": 2.7718470096588135,
      "learning_rate": 3.444180522565321e-05,
      "loss": 0.3328,
      "step": 290
    },
    {
      "epoch": 0.21321961620469082,
      "grad_norm": 4.024362564086914,
      "learning_rate": 3.5629453681710215e-05,
      "loss": 0.3519,
      "step": 300
    },
    {
      "epoch": 0.22032693674484718,
      "grad_norm": 4.726733684539795,
      "learning_rate": 3.681710213776722e-05,
      "loss": 0.2453,
      "step": 310
    },
    {
      "epoch": 0.22743425728500355,
      "grad_norm": 4.899835586547852,
      "learning_rate": 3.800475059382423e-05,
      "loss": 0.3468,
      "step": 320
    },
    {
      "epoch": 0.2345415778251599,
      "grad_norm": 2.7217540740966797,
      "learning_rate": 3.919239904988123e-05,
      "loss": 0.3005,
      "step": 330
    },
    {
      "epoch": 0.24164889836531628,
      "grad_norm": 6.257454872131348,
      "learning_rate": 4.0380047505938246e-05,
      "loss": 0.3682,
      "step": 340
    },
    {
      "epoch": 0.24875621890547264,
      "grad_norm": 2.2090303897857666,
      "learning_rate": 4.156769596199525e-05,
      "loss": 0.3873,
      "step": 350
    },
    {
      "epoch": 0.255863539445629,
      "grad_norm": 5.390707969665527,
      "learning_rate": 4.275534441805226e-05,
      "loss": 0.3325,
      "step": 360
    },
    {
      "epoch": 0.26297085998578534,
      "grad_norm": 2.519174337387085,
      "learning_rate": 4.394299287410927e-05,
      "loss": 0.2987,
      "step": 370
    },
    {
      "epoch": 0.27007818052594174,
      "grad_norm": 2.501490831375122,
      "learning_rate": 4.513064133016627e-05,
      "loss": 0.2898,
      "step": 380
    },
    {
      "epoch": 0.2771855010660981,
      "grad_norm": 2.2056262493133545,
      "learning_rate": 4.6318289786223276e-05,
      "loss": 0.3433,
      "step": 390
    },
    {
      "epoch": 0.28429282160625446,
      "grad_norm": 6.923454761505127,
      "learning_rate": 4.750593824228028e-05,
      "loss": 0.3164,
      "step": 400
    },
    {
      "epoch": 0.2914001421464108,
      "grad_norm": 9.64022159576416,
      "learning_rate": 4.8693586698337295e-05,
      "loss": 0.3755,
      "step": 410
    },
    {
      "epoch": 0.29850746268656714,
      "grad_norm": 4.991449356079102,
      "learning_rate": 4.98812351543943e-05,
      "loss": 0.2796,
      "step": 420
    },
    {
      "epoch": 0.30561478322672353,
      "grad_norm": 5.998867034912109,
      "learning_rate": 4.9881578947368425e-05,
      "loss": 0.3715,
      "step": 430
    },
    {
      "epoch": 0.31272210376687987,
      "grad_norm": 5.667739391326904,
      "learning_rate": 4.975e-05,
      "loss": 0.2542,
      "step": 440
    },
    {
      "epoch": 0.31982942430703626,
      "grad_norm": 5.550570487976074,
      "learning_rate": 4.961842105263158e-05,
      "loss": 0.3904,
      "step": 450
    },
    {
      "epoch": 0.3269367448471926,
      "grad_norm": 8.117775917053223,
      "learning_rate": 4.948684210526316e-05,
      "loss": 0.2519,
      "step": 460
    },
    {
      "epoch": 0.334044065387349,
      "grad_norm": 7.843630790710449,
      "learning_rate": 4.935526315789474e-05,
      "loss": 0.3189,
      "step": 470
    },
    {
      "epoch": 0.3411513859275053,
      "grad_norm": 2.288923978805542,
      "learning_rate": 4.9223684210526316e-05,
      "loss": 0.3157,
      "step": 480
    },
    {
      "epoch": 0.3482587064676617,
      "grad_norm": 1.9325124025344849,
      "learning_rate": 4.9092105263157894e-05,
      "loss": 0.3706,
      "step": 490
    },
    {
      "epoch": 0.35536602700781805,
      "grad_norm": 2.674156904220581,
      "learning_rate": 4.896052631578947e-05,
      "loss": 0.319,
      "step": 500
    },
    {
      "epoch": 0.3624733475479744,
      "grad_norm": 5.045976161956787,
      "learning_rate": 4.882894736842106e-05,
      "loss": 0.3339,
      "step": 510
    },
    {
      "epoch": 0.3695806680881308,
      "grad_norm": 3.9472484588623047,
      "learning_rate": 4.8697368421052636e-05,
      "loss": 0.2163,
      "step": 520
    },
    {
      "epoch": 0.3766879886282871,
      "grad_norm": 5.394717693328857,
      "learning_rate": 4.8565789473684214e-05,
      "loss": 0.4175,
      "step": 530
    },
    {
      "epoch": 0.3837953091684435,
      "grad_norm": 6.262406349182129,
      "learning_rate": 4.843421052631579e-05,
      "loss": 0.3121,
      "step": 540
    },
    {
      "epoch": 0.39090262970859985,
      "grad_norm": 6.164360046386719,
      "learning_rate": 4.830263157894737e-05,
      "loss": 0.3249,
      "step": 550
    },
    {
      "epoch": 0.39800995024875624,
      "grad_norm": 9.718866348266602,
      "learning_rate": 4.817105263157895e-05,
      "loss": 0.3576,
      "step": 560
    },
    {
      "epoch": 0.4051172707889126,
      "grad_norm": 5.971670150756836,
      "learning_rate": 4.803947368421053e-05,
      "loss": 0.3226,
      "step": 570
    },
    {
      "epoch": 0.41222459132906897,
      "grad_norm": 3.1125705242156982,
      "learning_rate": 4.7907894736842105e-05,
      "loss": 0.2725,
      "step": 580
    },
    {
      "epoch": 0.4193319118692253,
      "grad_norm": 4.04184627532959,
      "learning_rate": 4.7776315789473684e-05,
      "loss": 0.3089,
      "step": 590
    },
    {
      "epoch": 0.42643923240938164,
      "grad_norm": 2.561224937438965,
      "learning_rate": 4.764473684210526e-05,
      "loss": 0.325,
      "step": 600
    },
    {
      "epoch": 0.43354655294953803,
      "grad_norm": 3.3261706829071045,
      "learning_rate": 4.751315789473684e-05,
      "loss": 0.3446,
      "step": 610
    },
    {
      "epoch": 0.44065387348969437,
      "grad_norm": 3.924152135848999,
      "learning_rate": 4.738157894736842e-05,
      "loss": 0.2807,
      "step": 620
    },
    {
      "epoch": 0.44776119402985076,
      "grad_norm": 2.23335862159729,
      "learning_rate": 4.7249999999999997e-05,
      "loss": 0.3059,
      "step": 630
    },
    {
      "epoch": 0.4548685145700071,
      "grad_norm": 4.182961940765381,
      "learning_rate": 4.711842105263158e-05,
      "loss": 0.3992,
      "step": 640
    },
    {
      "epoch": 0.4619758351101635,
      "grad_norm": 4.688613414764404,
      "learning_rate": 4.698684210526316e-05,
      "loss": 0.3134,
      "step": 650
    },
    {
      "epoch": 0.4690831556503198,
      "grad_norm": 1.8492405414581299,
      "learning_rate": 4.685526315789474e-05,
      "loss": 0.2193,
      "step": 660
    },
    {
      "epoch": 0.47619047619047616,
      "grad_norm": 5.0105390548706055,
      "learning_rate": 4.6723684210526316e-05,
      "loss": 0.2758,
      "step": 670
    },
    {
      "epoch": 0.48329779673063256,
      "grad_norm": 6.5723958015441895,
      "learning_rate": 4.65921052631579e-05,
      "loss": 0.2321,
      "step": 680
    },
    {
      "epoch": 0.4904051172707889,
      "grad_norm": 7.94719934463501,
      "learning_rate": 4.646052631578948e-05,
      "loss": 0.3193,
      "step": 690
    },
    {
      "epoch": 0.4975124378109453,
      "grad_norm": 3.951179027557373,
      "learning_rate": 4.632894736842106e-05,
      "loss": 0.2433,
      "step": 700
    },
    {
      "epoch": 0.5046197583511016,
      "grad_norm": 4.8463311195373535,
      "learning_rate": 4.6197368421052636e-05,
      "loss": 0.2689,
      "step": 710
    },
    {
      "epoch": 0.511727078891258,
      "grad_norm": 3.1561691761016846,
      "learning_rate": 4.6065789473684214e-05,
      "loss": 0.3222,
      "step": 720
    },
    {
      "epoch": 0.5188343994314144,
      "grad_norm": 1.0864384174346924,
      "learning_rate": 4.593421052631579e-05,
      "loss": 0.1907,
      "step": 730
    },
    {
      "epoch": 0.5259417199715707,
      "grad_norm": 1.330297589302063,
      "learning_rate": 4.580263157894737e-05,
      "loss": 0.2139,
      "step": 740
    },
    {
      "epoch": 0.5330490405117271,
      "grad_norm": 1.2673184871673584,
      "learning_rate": 4.567105263157895e-05,
      "loss": 0.2246,
      "step": 750
    },
    {
      "epoch": 0.5401563610518835,
      "grad_norm": 3.660353422164917,
      "learning_rate": 4.553947368421053e-05,
      "loss": 0.333,
      "step": 760
    },
    {
      "epoch": 0.5472636815920398,
      "grad_norm": 1.6236813068389893,
      "learning_rate": 4.5407894736842106e-05,
      "loss": 0.3047,
      "step": 770
    },
    {
      "epoch": 0.5543710021321961,
      "grad_norm": 0.733258068561554,
      "learning_rate": 4.527631578947369e-05,
      "loss": 0.2031,
      "step": 780
    },
    {
      "epoch": 0.5614783226723525,
      "grad_norm": 6.871444225311279,
      "learning_rate": 4.514473684210527e-05,
      "loss": 0.3327,
      "step": 790
    },
    {
      "epoch": 0.5685856432125089,
      "grad_norm": 1.8644025325775146,
      "learning_rate": 4.501315789473685e-05,
      "loss": 0.3295,
      "step": 800
    },
    {
      "epoch": 0.5756929637526652,
      "grad_norm": 6.76733922958374,
      "learning_rate": 4.4881578947368425e-05,
      "loss": 0.347,
      "step": 810
    },
    {
      "epoch": 0.5828002842928216,
      "grad_norm": 3.8209919929504395,
      "learning_rate": 4.4750000000000004e-05,
      "loss": 0.3084,
      "step": 820
    },
    {
      "epoch": 0.589907604832978,
      "grad_norm": 2.0486080646514893,
      "learning_rate": 4.461842105263158e-05,
      "loss": 0.2658,
      "step": 830
    },
    {
      "epoch": 0.5970149253731343,
      "grad_norm": 8.4255952835083,
      "learning_rate": 4.448684210526316e-05,
      "loss": 0.2712,
      "step": 840
    },
    {
      "epoch": 0.6041222459132907,
      "grad_norm": 1.9007000923156738,
      "learning_rate": 4.435526315789474e-05,
      "loss": 0.2458,
      "step": 850
    },
    {
      "epoch": 0.6112295664534471,
      "grad_norm": 1.6504321098327637,
      "learning_rate": 4.4223684210526317e-05,
      "loss": 0.1856,
      "step": 860
    },
    {
      "epoch": 0.6183368869936035,
      "grad_norm": 3.5537304878234863,
      "learning_rate": 4.4092105263157895e-05,
      "loss": 0.3476,
      "step": 870
    },
    {
      "epoch": 0.6254442075337597,
      "grad_norm": 1.9437413215637207,
      "learning_rate": 4.396052631578947e-05,
      "loss": 0.3434,
      "step": 880
    },
    {
      "epoch": 0.6325515280739161,
      "grad_norm": 6.343731880187988,
      "learning_rate": 4.382894736842105e-05,
      "loss": 0.3709,
      "step": 890
    },
    {
      "epoch": 0.6396588486140725,
      "grad_norm": 1.0885382890701294,
      "learning_rate": 4.369736842105263e-05,
      "loss": 0.2641,
      "step": 900
    },
    {
      "epoch": 0.6467661691542289,
      "grad_norm": 3.1310012340545654,
      "learning_rate": 4.3565789473684215e-05,
      "loss": 0.2879,
      "step": 910
    },
    {
      "epoch": 0.6538734896943852,
      "grad_norm": 2.6443569660186768,
      "learning_rate": 4.343421052631579e-05,
      "loss": 0.2871,
      "step": 920
    },
    {
      "epoch": 0.6609808102345416,
      "grad_norm": 1.290907621383667,
      "learning_rate": 4.330263157894737e-05,
      "loss": 0.2255,
      "step": 930
    },
    {
      "epoch": 0.668088130774698,
      "grad_norm": 4.207393646240234,
      "learning_rate": 4.317105263157895e-05,
      "loss": 0.3429,
      "step": 940
    },
    {
      "epoch": 0.6751954513148543,
      "grad_norm": 2.4924087524414062,
      "learning_rate": 4.303947368421053e-05,
      "loss": 0.2385,
      "step": 950
    },
    {
      "epoch": 0.6823027718550106,
      "grad_norm": 2.008599042892456,
      "learning_rate": 4.2907894736842106e-05,
      "loss": 0.2812,
      "step": 960
    },
    {
      "epoch": 0.689410092395167,
      "grad_norm": 3.8274593353271484,
      "learning_rate": 4.2776315789473684e-05,
      "loss": 0.3223,
      "step": 970
    },
    {
      "epoch": 0.6965174129353234,
      "grad_norm": 1.7950327396392822,
      "learning_rate": 4.264473684210526e-05,
      "loss": 0.1991,
      "step": 980
    },
    {
      "epoch": 0.7036247334754797,
      "grad_norm": 10.735652923583984,
      "learning_rate": 4.251315789473684e-05,
      "loss": 0.2361,
      "step": 990
    },
    {
      "epoch": 0.7107320540156361,
      "grad_norm": 0.7412087321281433,
      "learning_rate": 4.2381578947368426e-05,
      "loss": 0.2064,
      "step": 1000
    },
    {
      "epoch": 0.7178393745557925,
      "grad_norm": 0.33822453022003174,
      "learning_rate": 4.2250000000000004e-05,
      "loss": 0.2571,
      "step": 1010
    },
    {
      "epoch": 0.7249466950959488,
      "grad_norm": 9.132181167602539,
      "learning_rate": 4.211842105263158e-05,
      "loss": 0.421,
      "step": 1020
    },
    {
      "epoch": 0.7320540156361052,
      "grad_norm": 2.2566213607788086,
      "learning_rate": 4.198684210526316e-05,
      "loss": 0.2296,
      "step": 1030
    },
    {
      "epoch": 0.7391613361762616,
      "grad_norm": 2.5582404136657715,
      "learning_rate": 4.185526315789474e-05,
      "loss": 0.3279,
      "step": 1040
    },
    {
      "epoch": 0.746268656716418,
      "grad_norm": 2.088041067123413,
      "learning_rate": 4.1723684210526324e-05,
      "loss": 0.2284,
      "step": 1050
    },
    {
      "epoch": 0.7533759772565742,
      "grad_norm": 3.8046681880950928,
      "learning_rate": 4.15921052631579e-05,
      "loss": 0.2638,
      "step": 1060
    },
    {
      "epoch": 0.7604832977967306,
      "grad_norm": 1.6764944791793823,
      "learning_rate": 4.146052631578948e-05,
      "loss": 0.229,
      "step": 1070
    },
    {
      "epoch": 0.767590618336887,
      "grad_norm": 1.4182195663452148,
      "learning_rate": 4.132894736842106e-05,
      "loss": 0.2927,
      "step": 1080
    },
    {
      "epoch": 0.7746979388770433,
      "grad_norm": 2.1676807403564453,
      "learning_rate": 4.1197368421052636e-05,
      "loss": 0.1989,
      "step": 1090
    },
    {
      "epoch": 0.7818052594171997,
      "grad_norm": 7.187459468841553,
      "learning_rate": 4.1065789473684215e-05,
      "loss": 0.3146,
      "step": 1100
    },
    {
      "epoch": 0.7889125799573561,
      "grad_norm": 4.405439376831055,
      "learning_rate": 4.093421052631579e-05,
      "loss": 0.2824,
      "step": 1110
    },
    {
      "epoch": 0.7960199004975125,
      "grad_norm": 9.812396049499512,
      "learning_rate": 4.080263157894737e-05,
      "loss": 0.3045,
      "step": 1120
    },
    {
      "epoch": 0.8031272210376688,
      "grad_norm": 2.0270044803619385,
      "learning_rate": 4.067105263157895e-05,
      "loss": 0.2199,
      "step": 1130
    },
    {
      "epoch": 0.8102345415778252,
      "grad_norm": 3.854360580444336,
      "learning_rate": 4.053947368421053e-05,
      "loss": 0.2942,
      "step": 1140
    },
    {
      "epoch": 0.8173418621179815,
      "grad_norm": 2.1559250354766846,
      "learning_rate": 4.0407894736842106e-05,
      "loss": 0.2663,
      "step": 1150
    },
    {
      "epoch": 0.8244491826581379,
      "grad_norm": 3.538825273513794,
      "learning_rate": 4.0276315789473684e-05,
      "loss": 0.2786,
      "step": 1160
    },
    {
      "epoch": 0.8315565031982942,
      "grad_norm": 2.7436070442199707,
      "learning_rate": 4.014473684210526e-05,
      "loss": 0.2341,
      "step": 1170
    },
    {
      "epoch": 0.8386638237384506,
      "grad_norm": 3.6034693717956543,
      "learning_rate": 4.001315789473684e-05,
      "loss": 0.167,
      "step": 1180
    },
    {
      "epoch": 0.845771144278607,
      "grad_norm": 1.6641169786453247,
      "learning_rate": 3.9881578947368426e-05,
      "loss": 0.2372,
      "step": 1190
    },
    {
      "epoch": 0.8528784648187633,
      "grad_norm": 8.15063190460205,
      "learning_rate": 3.9750000000000004e-05,
      "loss": 0.4378,
      "step": 1200
    },
    {
      "epoch": 0.8599857853589197,
      "grad_norm": 1.3333150148391724,
      "learning_rate": 3.961842105263158e-05,
      "loss": 0.244,
      "step": 1210
    },
    {
      "epoch": 0.8670931058990761,
      "grad_norm": 2.7276203632354736,
      "learning_rate": 3.948684210526316e-05,
      "loss": 0.254,
      "step": 1220
    },
    {
      "epoch": 0.8742004264392325,
      "grad_norm": 4.079287528991699,
      "learning_rate": 3.935526315789474e-05,
      "loss": 0.2366,
      "step": 1230
    },
    {
      "epoch": 0.8813077469793887,
      "grad_norm": 2.838575601577759,
      "learning_rate": 3.922368421052632e-05,
      "loss": 0.2379,
      "step": 1240
    },
    {
      "epoch": 0.8884150675195451,
      "grad_norm": 1.3774826526641846,
      "learning_rate": 3.9092105263157895e-05,
      "loss": 0.2413,
      "step": 1250
    },
    {
      "epoch": 0.8955223880597015,
      "grad_norm": 1.1256725788116455,
      "learning_rate": 3.8960526315789473e-05,
      "loss": 0.2206,
      "step": 1260
    },
    {
      "epoch": 0.9026297085998578,
      "grad_norm": 5.647760391235352,
      "learning_rate": 3.882894736842105e-05,
      "loss": 0.3458,
      "step": 1270
    },
    {
      "epoch": 0.9097370291400142,
      "grad_norm": 2.3039329051971436,
      "learning_rate": 3.869736842105263e-05,
      "loss": 0.3205,
      "step": 1280
    },
    {
      "epoch": 0.9168443496801706,
      "grad_norm": 4.309289932250977,
      "learning_rate": 3.856578947368421e-05,
      "loss": 0.2834,
      "step": 1290
    },
    {
      "epoch": 0.923951670220327,
      "grad_norm": 3.118396282196045,
      "learning_rate": 3.8434210526315786e-05,
      "loss": 0.3476,
      "step": 1300
    },
    {
      "epoch": 0.9310589907604833,
      "grad_norm": 4.317744731903076,
      "learning_rate": 3.8302631578947365e-05,
      "loss": 0.3108,
      "step": 1310
    },
    {
      "epoch": 0.9381663113006397,
      "grad_norm": 3.824692726135254,
      "learning_rate": 3.817105263157895e-05,
      "loss": 0.2096,
      "step": 1320
    },
    {
      "epoch": 0.945273631840796,
      "grad_norm": 4.6562180519104,
      "learning_rate": 3.803947368421053e-05,
      "loss": 0.2047,
      "step": 1330
    },
    {
      "epoch": 0.9523809523809523,
      "grad_norm": 1.304869532585144,
      "learning_rate": 3.7907894736842106e-05,
      "loss": 0.2882,
      "step": 1340
    },
    {
      "epoch": 0.9594882729211087,
      "grad_norm": 4.33357048034668,
      "learning_rate": 3.7776315789473684e-05,
      "loss": 0.3279,
      "step": 1350
    },
    {
      "epoch": 0.9665955934612651,
      "grad_norm": 1.6882264614105225,
      "learning_rate": 3.764473684210526e-05,
      "loss": 0.2399,
      "step": 1360
    },
    {
      "epoch": 0.9737029140014215,
      "grad_norm": 5.81782865524292,
      "learning_rate": 3.751315789473685e-05,
      "loss": 0.2859,
      "step": 1370
    },
    {
      "epoch": 0.9808102345415778,
      "grad_norm": 3.4679417610168457,
      "learning_rate": 3.7381578947368426e-05,
      "loss": 0.3001,
      "step": 1380
    },
    {
      "epoch": 0.9879175550817342,
      "grad_norm": 2.9034414291381836,
      "learning_rate": 3.7250000000000004e-05,
      "loss": 0.3453,
      "step": 1390
    },
    {
      "epoch": 0.9950248756218906,
      "grad_norm": 2.6851634979248047,
      "learning_rate": 3.711842105263158e-05,
      "loss": 0.2579,
      "step": 1400
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.89,
      "eval_f1": 0.8925361469323955,
      "eval_loss": 0.25772756338119507,
      "eval_precision": 0.8724216959511077,
      "eval_recall": 0.9136,
      "eval_runtime": 26.2764,
      "eval_samples_per_second": 95.142,
      "eval_steps_per_second": 5.975,
      "step": 1407
    },
    {
      "epoch": 1.0021321961620469,
      "grad_norm": 3.793579578399658,
      "learning_rate": 3.698684210526316e-05,
      "loss": 0.2216,
      "step": 1410
    },
    {
      "epoch": 1.0092395167022032,
      "grad_norm": 4.3174543380737305,
      "learning_rate": 3.685526315789474e-05,
      "loss": 0.2163,
      "step": 1420
    },
    {
      "epoch": 1.0163468372423596,
      "grad_norm": 3.404479503631592,
      "learning_rate": 3.672368421052632e-05,
      "loss": 0.2192,
      "step": 1430
    },
    {
      "epoch": 1.023454157782516,
      "grad_norm": 0.657733142375946,
      "learning_rate": 3.6592105263157895e-05,
      "loss": 0.2065,
      "step": 1440
    },
    {
      "epoch": 1.0305614783226724,
      "grad_norm": 3.703303098678589,
      "learning_rate": 3.6460526315789474e-05,
      "loss": 0.3295,
      "step": 1450
    },
    {
      "epoch": 1.0376687988628288,
      "grad_norm": 7.082793235778809,
      "learning_rate": 3.632894736842106e-05,
      "loss": 0.2282,
      "step": 1460
    },
    {
      "epoch": 1.044776119402985,
      "grad_norm": 1.5929033756256104,
      "learning_rate": 3.619736842105264e-05,
      "loss": 0.2657,
      "step": 1470
    },
    {
      "epoch": 1.0518834399431414,
      "grad_norm": 3.138312339782715,
      "learning_rate": 3.6065789473684215e-05,
      "loss": 0.2359,
      "step": 1480
    },
    {
      "epoch": 1.0589907604832978,
      "grad_norm": 1.545058012008667,
      "learning_rate": 3.5934210526315793e-05,
      "loss": 0.2327,
      "step": 1490
    },
    {
      "epoch": 1.0660980810234542,
      "grad_norm": 1.2006055116653442,
      "learning_rate": 3.580263157894737e-05,
      "loss": 0.2877,
      "step": 1500
    },
    {
      "epoch": 1.0732054015636106,
      "grad_norm": 7.101900577545166,
      "learning_rate": 3.567105263157895e-05,
      "loss": 0.2044,
      "step": 1510
    },
    {
      "epoch": 1.080312722103767,
      "grad_norm": 3.694319486618042,
      "learning_rate": 3.553947368421053e-05,
      "loss": 0.3193,
      "step": 1520
    },
    {
      "epoch": 1.0874200426439233,
      "grad_norm": 4.273890018463135,
      "learning_rate": 3.5407894736842106e-05,
      "loss": 0.3226,
      "step": 1530
    },
    {
      "epoch": 1.0945273631840795,
      "grad_norm": 1.5978341102600098,
      "learning_rate": 3.5276315789473685e-05,
      "loss": 0.226,
      "step": 1540
    },
    {
      "epoch": 1.101634683724236,
      "grad_norm": 3.4300689697265625,
      "learning_rate": 3.514473684210526e-05,
      "loss": 0.3363,
      "step": 1550
    },
    {
      "epoch": 1.1087420042643923,
      "grad_norm": 7.741127967834473,
      "learning_rate": 3.501315789473684e-05,
      "loss": 0.2029,
      "step": 1560
    },
    {
      "epoch": 1.1158493248045487,
      "grad_norm": 4.822306156158447,
      "learning_rate": 3.488157894736842e-05,
      "loss": 0.2253,
      "step": 1570
    },
    {
      "epoch": 1.122956645344705,
      "grad_norm": 2.4434854984283447,
      "learning_rate": 3.475e-05,
      "loss": 0.2886,
      "step": 1580
    },
    {
      "epoch": 1.1300639658848615,
      "grad_norm": 2.9445090293884277,
      "learning_rate": 3.461842105263158e-05,
      "loss": 0.1553,
      "step": 1590
    },
    {
      "epoch": 1.1371712864250179,
      "grad_norm": 1.0357704162597656,
      "learning_rate": 3.448684210526316e-05,
      "loss": 0.2762,
      "step": 1600
    },
    {
      "epoch": 1.144278606965174,
      "grad_norm": 4.330826759338379,
      "learning_rate": 3.435526315789474e-05,
      "loss": 0.1937,
      "step": 1610
    },
    {
      "epoch": 1.1513859275053304,
      "grad_norm": 2.3939201831817627,
      "learning_rate": 3.422368421052632e-05,
      "loss": 0.2321,
      "step": 1620
    },
    {
      "epoch": 1.1584932480454868,
      "grad_norm": 6.7557830810546875,
      "learning_rate": 3.4092105263157896e-05,
      "loss": 0.2478,
      "step": 1630
    },
    {
      "epoch": 1.1656005685856432,
      "grad_norm": 10.910487174987793,
      "learning_rate": 3.3960526315789474e-05,
      "loss": 0.2903,
      "step": 1640
    },
    {
      "epoch": 1.1727078891257996,
      "grad_norm": 6.098073482513428,
      "learning_rate": 3.382894736842105e-05,
      "loss": 0.2127,
      "step": 1650
    },
    {
      "epoch": 1.179815209665956,
      "grad_norm": 4.046130180358887,
      "learning_rate": 3.369736842105263e-05,
      "loss": 0.2538,
      "step": 1660
    },
    {
      "epoch": 1.1869225302061124,
      "grad_norm": 2.0741262435913086,
      "learning_rate": 3.356578947368421e-05,
      "loss": 0.1839,
      "step": 1670
    },
    {
      "epoch": 1.1940298507462686,
      "grad_norm": 2.536003828048706,
      "learning_rate": 3.343421052631579e-05,
      "loss": 0.2203,
      "step": 1680
    },
    {
      "epoch": 1.201137171286425,
      "grad_norm": 2.146042585372925,
      "learning_rate": 3.330263157894737e-05,
      "loss": 0.2183,
      "step": 1690
    },
    {
      "epoch": 1.2082444918265813,
      "grad_norm": 4.157567977905273,
      "learning_rate": 3.317105263157895e-05,
      "loss": 0.2512,
      "step": 1700
    },
    {
      "epoch": 1.2153518123667377,
      "grad_norm": 2.9470837116241455,
      "learning_rate": 3.303947368421053e-05,
      "loss": 0.3179,
      "step": 1710
    },
    {
      "epoch": 1.2224591329068941,
      "grad_norm": 3.6047775745391846,
      "learning_rate": 3.290789473684211e-05,
      "loss": 0.3446,
      "step": 1720
    },
    {
      "epoch": 1.2295664534470505,
      "grad_norm": 2.1411168575286865,
      "learning_rate": 3.277631578947369e-05,
      "loss": 0.2182,
      "step": 1730
    },
    {
      "epoch": 1.236673773987207,
      "grad_norm": 3.097111463546753,
      "learning_rate": 3.264473684210527e-05,
      "loss": 0.2691,
      "step": 1740
    },
    {
      "epoch": 1.243781094527363,
      "grad_norm": 0.6328858137130737,
      "learning_rate": 3.251315789473685e-05,
      "loss": 0.2689,
      "step": 1750
    },
    {
      "epoch": 1.2508884150675195,
      "grad_norm": 1.7755683660507202,
      "learning_rate": 3.2381578947368426e-05,
      "loss": 0.2424,
      "step": 1760
    },
    {
      "epoch": 1.2579957356076759,
      "grad_norm": 1.9455580711364746,
      "learning_rate": 3.2250000000000005e-05,
      "loss": 0.323,
      "step": 1770
    },
    {
      "epoch": 1.2651030561478323,
      "grad_norm": 4.141851425170898,
      "learning_rate": 3.211842105263158e-05,
      "loss": 0.2563,
      "step": 1780
    },
    {
      "epoch": 1.2722103766879886,
      "grad_norm": 3.1684410572052,
      "learning_rate": 3.198684210526316e-05,
      "loss": 0.2308,
      "step": 1790
    },
    {
      "epoch": 1.279317697228145,
      "grad_norm": 1.7720035314559937,
      "learning_rate": 3.185526315789474e-05,
      "loss": 0.2011,
      "step": 1800
    },
    {
      "epoch": 1.2864250177683014,
      "grad_norm": 2.589958667755127,
      "learning_rate": 3.172368421052632e-05,
      "loss": 0.2662,
      "step": 1810
    },
    {
      "epoch": 1.2935323383084576,
      "grad_norm": 2.5457613468170166,
      "learning_rate": 3.1592105263157896e-05,
      "loss": 0.2612,
      "step": 1820
    },
    {
      "epoch": 1.3006396588486142,
      "grad_norm": 5.333953857421875,
      "learning_rate": 3.1460526315789474e-05,
      "loss": 0.1807,
      "step": 1830
    },
    {
      "epoch": 1.3077469793887704,
      "grad_norm": 3.2483415603637695,
      "learning_rate": 3.132894736842105e-05,
      "loss": 0.2285,
      "step": 1840
    },
    {
      "epoch": 1.3148542999289268,
      "grad_norm": 4.560727596282959,
      "learning_rate": 3.119736842105263e-05,
      "loss": 0.2511,
      "step": 1850
    },
    {
      "epoch": 1.3219616204690832,
      "grad_norm": 7.185634136199951,
      "learning_rate": 3.1065789473684216e-05,
      "loss": 0.2675,
      "step": 1860
    },
    {
      "epoch": 1.3290689410092396,
      "grad_norm": 3.519988775253296,
      "learning_rate": 3.0934210526315794e-05,
      "loss": 0.2268,
      "step": 1870
    },
    {
      "epoch": 1.336176261549396,
      "grad_norm": 3.734890937805176,
      "learning_rate": 3.080263157894737e-05,
      "loss": 0.2893,
      "step": 1880
    },
    {
      "epoch": 1.3432835820895521,
      "grad_norm": 5.669505596160889,
      "learning_rate": 3.067105263157895e-05,
      "loss": 0.3075,
      "step": 1890
    },
    {
      "epoch": 1.3503909026297087,
      "grad_norm": 4.109992027282715,
      "learning_rate": 3.053947368421053e-05,
      "loss": 0.2155,
      "step": 1900
    },
    {
      "epoch": 1.357498223169865,
      "grad_norm": 2.9438469409942627,
      "learning_rate": 3.0407894736842107e-05,
      "loss": 0.3198,
      "step": 1910
    },
    {
      "epoch": 1.3646055437100213,
      "grad_norm": 3.634521722793579,
      "learning_rate": 3.0276315789473685e-05,
      "loss": 0.2442,
      "step": 1920
    },
    {
      "epoch": 1.3717128642501777,
      "grad_norm": 2.9953436851501465,
      "learning_rate": 3.0144736842105263e-05,
      "loss": 0.2108,
      "step": 1930
    },
    {
      "epoch": 1.378820184790334,
      "grad_norm": 3.3080363273620605,
      "learning_rate": 3.001315789473684e-05,
      "loss": 0.1952,
      "step": 1940
    },
    {
      "epoch": 1.3859275053304905,
      "grad_norm": 5.806305408477783,
      "learning_rate": 2.9881578947368423e-05,
      "loss": 0.2693,
      "step": 1950
    },
    {
      "epoch": 1.3930348258706466,
      "grad_norm": 6.529880046844482,
      "learning_rate": 2.975e-05,
      "loss": 0.2171,
      "step": 1960
    },
    {
      "epoch": 1.4001421464108033,
      "grad_norm": 4.068181991577148,
      "learning_rate": 2.961842105263158e-05,
      "loss": 0.2956,
      "step": 1970
    },
    {
      "epoch": 1.4072494669509594,
      "grad_norm": 4.2109599113464355,
      "learning_rate": 2.9486842105263158e-05,
      "loss": 0.3284,
      "step": 1980
    },
    {
      "epoch": 1.4143567874911158,
      "grad_norm": 3.0381481647491455,
      "learning_rate": 2.9355263157894736e-05,
      "loss": 0.1549,
      "step": 1990
    },
    {
      "epoch": 1.4214641080312722,
      "grad_norm": 1.5666879415512085,
      "learning_rate": 2.922368421052632e-05,
      "loss": 0.2103,
      "step": 2000
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 3.5578951835632324,
      "learning_rate": 2.90921052631579e-05,
      "loss": 0.2652,
      "step": 2010
    },
    {
      "epoch": 1.435678749111585,
      "grad_norm": 2.7619407176971436,
      "learning_rate": 2.8960526315789478e-05,
      "loss": 0.1918,
      "step": 2020
    },
    {
      "epoch": 1.4427860696517412,
      "grad_norm": 2.652261972427368,
      "learning_rate": 2.8828947368421056e-05,
      "loss": 0.2345,
      "step": 2030
    },
    {
      "epoch": 1.4498933901918978,
      "grad_norm": 1.6996967792510986,
      "learning_rate": 2.8697368421052634e-05,
      "loss": 0.3417,
      "step": 2040
    },
    {
      "epoch": 1.457000710732054,
      "grad_norm": 3.178098440170288,
      "learning_rate": 2.8565789473684212e-05,
      "loss": 0.2301,
      "step": 2050
    },
    {
      "epoch": 1.4641080312722103,
      "grad_norm": 3.5727219581604004,
      "learning_rate": 2.843421052631579e-05,
      "loss": 0.2629,
      "step": 2060
    },
    {
      "epoch": 1.4712153518123667,
      "grad_norm": 2.322671890258789,
      "learning_rate": 2.830263157894737e-05,
      "loss": 0.1728,
      "step": 2070
    },
    {
      "epoch": 1.4783226723525231,
      "grad_norm": 4.909292221069336,
      "learning_rate": 2.8171052631578947e-05,
      "loss": 0.417,
      "step": 2080
    },
    {
      "epoch": 1.4854299928926795,
      "grad_norm": 5.114230632781982,
      "learning_rate": 2.8039473684210525e-05,
      "loss": 0.2574,
      "step": 2090
    },
    {
      "epoch": 1.4925373134328357,
      "grad_norm": 3.8492746353149414,
      "learning_rate": 2.7907894736842104e-05,
      "loss": 0.1799,
      "step": 2100
    },
    {
      "epoch": 1.4996446339729923,
      "grad_norm": 3.2957308292388916,
      "learning_rate": 2.7776315789473685e-05,
      "loss": 0.1456,
      "step": 2110
    },
    {
      "epoch": 1.5067519545131485,
      "grad_norm": 4.799927711486816,
      "learning_rate": 2.7644736842105264e-05,
      "loss": 0.2494,
      "step": 2120
    },
    {
      "epoch": 1.5138592750533049,
      "grad_norm": 0.9411325454711914,
      "learning_rate": 2.7513157894736842e-05,
      "loss": 0.2646,
      "step": 2130
    },
    {
      "epoch": 1.5209665955934613,
      "grad_norm": 5.631038188934326,
      "learning_rate": 2.7381578947368423e-05,
      "loss": 0.1745,
      "step": 2140
    },
    {
      "epoch": 1.5280739161336176,
      "grad_norm": 2.2165844440460205,
      "learning_rate": 2.725e-05,
      "loss": 0.222,
      "step": 2150
    },
    {
      "epoch": 1.535181236673774,
      "grad_norm": 4.229945182800293,
      "learning_rate": 2.7118421052631583e-05,
      "loss": 0.3043,
      "step": 2160
    },
    {
      "epoch": 1.5422885572139302,
      "grad_norm": 3.448711633682251,
      "learning_rate": 2.698684210526316e-05,
      "loss": 0.2165,
      "step": 2170
    },
    {
      "epoch": 1.5493958777540868,
      "grad_norm": 4.016654968261719,
      "learning_rate": 2.685526315789474e-05,
      "loss": 0.2246,
      "step": 2180
    },
    {
      "epoch": 1.556503198294243,
      "grad_norm": 3.1339986324310303,
      "learning_rate": 2.6723684210526318e-05,
      "loss": 0.2391,
      "step": 2190
    },
    {
      "epoch": 1.5636105188343994,
      "grad_norm": 2.353510618209839,
      "learning_rate": 2.6592105263157896e-05,
      "loss": 0.3354,
      "step": 2200
    },
    {
      "epoch": 1.5707178393745558,
      "grad_norm": 3.5594868659973145,
      "learning_rate": 2.6460526315789475e-05,
      "loss": 0.2062,
      "step": 2210
    },
    {
      "epoch": 1.5778251599147122,
      "grad_norm": 5.032797813415527,
      "learning_rate": 2.6328947368421053e-05,
      "loss": 0.2496,
      "step": 2220
    },
    {
      "epoch": 1.5849324804548686,
      "grad_norm": 0.8426063656806946,
      "learning_rate": 2.619736842105263e-05,
      "loss": 0.1912,
      "step": 2230
    },
    {
      "epoch": 1.5920398009950247,
      "grad_norm": 1.1189887523651123,
      "learning_rate": 2.606578947368421e-05,
      "loss": 0.2263,
      "step": 2240
    },
    {
      "epoch": 1.5991471215351813,
      "grad_norm": 6.07562780380249,
      "learning_rate": 2.5934210526315788e-05,
      "loss": 0.2654,
      "step": 2250
    },
    {
      "epoch": 1.6062544420753375,
      "grad_norm": 4.527456283569336,
      "learning_rate": 2.5802631578947366e-05,
      "loss": 0.207,
      "step": 2260
    },
    {
      "epoch": 1.613361762615494,
      "grad_norm": 2.1448047161102295,
      "learning_rate": 2.567105263157895e-05,
      "loss": 0.1378,
      "step": 2270
    },
    {
      "epoch": 1.6204690831556503,
      "grad_norm": 2.861673355102539,
      "learning_rate": 2.553947368421053e-05,
      "loss": 0.2529,
      "step": 2280
    },
    {
      "epoch": 1.6275764036958067,
      "grad_norm": 3.847318410873413,
      "learning_rate": 2.5407894736842107e-05,
      "loss": 0.2545,
      "step": 2290
    },
    {
      "epoch": 1.634683724235963,
      "grad_norm": 4.964937210083008,
      "learning_rate": 2.5276315789473686e-05,
      "loss": 0.1133,
      "step": 2300
    },
    {
      "epoch": 1.6417910447761193,
      "grad_norm": 3.343111991882324,
      "learning_rate": 2.5144736842105264e-05,
      "loss": 0.2731,
      "step": 2310
    },
    {
      "epoch": 1.6488983653162759,
      "grad_norm": 3.0687644481658936,
      "learning_rate": 2.5013157894736845e-05,
      "loss": 0.1793,
      "step": 2320
    },
    {
      "epoch": 1.656005685856432,
      "grad_norm": 7.275823593139648,
      "learning_rate": 2.4881578947368424e-05,
      "loss": 0.239,
      "step": 2330
    },
    {
      "epoch": 1.6631130063965884,
      "grad_norm": 0.2020268589258194,
      "learning_rate": 2.4750000000000002e-05,
      "loss": 0.2194,
      "step": 2340
    },
    {
      "epoch": 1.6702203269367448,
      "grad_norm": 0.7004907131195068,
      "learning_rate": 2.461842105263158e-05,
      "loss": 0.143,
      "step": 2350
    },
    {
      "epoch": 1.6773276474769012,
      "grad_norm": 6.858715534210205,
      "learning_rate": 2.448684210526316e-05,
      "loss": 0.2046,
      "step": 2360
    },
    {
      "epoch": 1.6844349680170576,
      "grad_norm": 2.3254053592681885,
      "learning_rate": 2.435526315789474e-05,
      "loss": 0.2665,
      "step": 2370
    },
    {
      "epoch": 1.6915422885572138,
      "grad_norm": 3.523761510848999,
      "learning_rate": 2.4223684210526318e-05,
      "loss": 0.135,
      "step": 2380
    },
    {
      "epoch": 1.6986496090973704,
      "grad_norm": 3.138049602508545,
      "learning_rate": 2.4092105263157897e-05,
      "loss": 0.3142,
      "step": 2390
    },
    {
      "epoch": 1.7057569296375266,
      "grad_norm": 3.7495601177215576,
      "learning_rate": 2.3960526315789475e-05,
      "loss": 0.2822,
      "step": 2400
    },
    {
      "epoch": 1.7128642501776832,
      "grad_norm": 3.083022117614746,
      "learning_rate": 2.3828947368421053e-05,
      "loss": 0.322,
      "step": 2410
    },
    {
      "epoch": 1.7199715707178393,
      "grad_norm": 6.77858829498291,
      "learning_rate": 2.369736842105263e-05,
      "loss": 0.2558,
      "step": 2420
    },
    {
      "epoch": 1.7270788912579957,
      "grad_norm": 2.77769136428833,
      "learning_rate": 2.356578947368421e-05,
      "loss": 0.2508,
      "step": 2430
    },
    {
      "epoch": 1.7341862117981521,
      "grad_norm": 1.867080807685852,
      "learning_rate": 2.343421052631579e-05,
      "loss": 0.2716,
      "step": 2440
    },
    {
      "epoch": 1.7412935323383083,
      "grad_norm": 2.077763557434082,
      "learning_rate": 2.330263157894737e-05,
      "loss": 0.2053,
      "step": 2450
    },
    {
      "epoch": 1.748400852878465,
      "grad_norm": 1.7868210077285767,
      "learning_rate": 2.3171052631578948e-05,
      "loss": 0.2404,
      "step": 2460
    },
    {
      "epoch": 1.755508173418621,
      "grad_norm": 4.219913959503174,
      "learning_rate": 2.3039473684210526e-05,
      "loss": 0.2702,
      "step": 2470
    },
    {
      "epoch": 1.7626154939587777,
      "grad_norm": 2.526441812515259,
      "learning_rate": 2.2907894736842108e-05,
      "loss": 0.2956,
      "step": 2480
    },
    {
      "epoch": 1.7697228144989339,
      "grad_norm": 3.2083938121795654,
      "learning_rate": 2.2776315789473686e-05,
      "loss": 0.243,
      "step": 2490
    },
    {
      "epoch": 1.7768301350390903,
      "grad_norm": 6.562258243560791,
      "learning_rate": 2.2644736842105264e-05,
      "loss": 0.2999,
      "step": 2500
    },
    {
      "epoch": 1.7839374555792467,
      "grad_norm": 0.8478699326515198,
      "learning_rate": 2.2513157894736846e-05,
      "loss": 0.2228,
      "step": 2510
    },
    {
      "epoch": 1.7910447761194028,
      "grad_norm": 7.054643154144287,
      "learning_rate": 2.2381578947368424e-05,
      "loss": 0.2277,
      "step": 2520
    },
    {
      "epoch": 1.7981520966595594,
      "grad_norm": 4.350286960601807,
      "learning_rate": 2.2250000000000002e-05,
      "loss": 0.2733,
      "step": 2530
    },
    {
      "epoch": 1.8052594171997156,
      "grad_norm": 2.7146639823913574,
      "learning_rate": 2.211842105263158e-05,
      "loss": 0.2293,
      "step": 2540
    },
    {
      "epoch": 1.8123667377398722,
      "grad_norm": 3.4001247882843018,
      "learning_rate": 2.198684210526316e-05,
      "loss": 0.229,
      "step": 2550
    },
    {
      "epoch": 1.8194740582800284,
      "grad_norm": 0.5263732671737671,
      "learning_rate": 2.1855263157894737e-05,
      "loss": 0.2116,
      "step": 2560
    },
    {
      "epoch": 1.8265813788201848,
      "grad_norm": 2.533806085586548,
      "learning_rate": 2.1723684210526315e-05,
      "loss": 0.3046,
      "step": 2570
    },
    {
      "epoch": 1.8336886993603412,
      "grad_norm": 5.011928558349609,
      "learning_rate": 2.1592105263157897e-05,
      "loss": 0.3171,
      "step": 2580
    },
    {
      "epoch": 1.8407960199004973,
      "grad_norm": 2.181133270263672,
      "learning_rate": 2.1460526315789475e-05,
      "loss": 0.2725,
      "step": 2590
    },
    {
      "epoch": 1.847903340440654,
      "grad_norm": 3.8776519298553467,
      "learning_rate": 2.1328947368421053e-05,
      "loss": 0.233,
      "step": 2600
    },
    {
      "epoch": 1.8550106609808101,
      "grad_norm": 5.385402679443359,
      "learning_rate": 2.119736842105263e-05,
      "loss": 0.2111,
      "step": 2610
    },
    {
      "epoch": 1.8621179815209667,
      "grad_norm": 0.7967531681060791,
      "learning_rate": 2.106578947368421e-05,
      "loss": 0.1463,
      "step": 2620
    },
    {
      "epoch": 1.869225302061123,
      "grad_norm": 5.762551307678223,
      "learning_rate": 2.0934210526315788e-05,
      "loss": 0.2408,
      "step": 2630
    },
    {
      "epoch": 1.8763326226012793,
      "grad_norm": 1.8894364833831787,
      "learning_rate": 2.080263157894737e-05,
      "loss": 0.3011,
      "step": 2640
    },
    {
      "epoch": 1.8834399431414357,
      "grad_norm": 2.0554144382476807,
      "learning_rate": 2.0671052631578948e-05,
      "loss": 0.2499,
      "step": 2650
    },
    {
      "epoch": 1.890547263681592,
      "grad_norm": 3.402318000793457,
      "learning_rate": 2.053947368421053e-05,
      "loss": 0.249,
      "step": 2660
    },
    {
      "epoch": 1.8976545842217485,
      "grad_norm": 4.904726982116699,
      "learning_rate": 2.0407894736842108e-05,
      "loss": 0.2136,
      "step": 2670
    },
    {
      "epoch": 1.9047619047619047,
      "grad_norm": 4.702792644500732,
      "learning_rate": 2.0276315789473686e-05,
      "loss": 0.1841,
      "step": 2680
    },
    {
      "epoch": 1.9118692253020613,
      "grad_norm": 2.029761791229248,
      "learning_rate": 2.0144736842105264e-05,
      "loss": 0.2484,
      "step": 2690
    },
    {
      "epoch": 1.9189765458422174,
      "grad_norm": 4.413347244262695,
      "learning_rate": 2.0013157894736842e-05,
      "loss": 0.3175,
      "step": 2700
    },
    {
      "epoch": 1.9260838663823738,
      "grad_norm": 3.3358731269836426,
      "learning_rate": 1.9881578947368424e-05,
      "loss": 0.2726,
      "step": 2710
    },
    {
      "epoch": 1.9331911869225302,
      "grad_norm": 1.5582445859909058,
      "learning_rate": 1.9750000000000002e-05,
      "loss": 0.1691,
      "step": 2720
    },
    {
      "epoch": 1.9402985074626866,
      "grad_norm": 2.6982264518737793,
      "learning_rate": 1.961842105263158e-05,
      "loss": 0.206,
      "step": 2730
    },
    {
      "epoch": 1.947405828002843,
      "grad_norm": 2.72930645942688,
      "learning_rate": 1.948684210526316e-05,
      "loss": 0.2283,
      "step": 2740
    },
    {
      "epoch": 1.9545131485429992,
      "grad_norm": 5.694418907165527,
      "learning_rate": 1.9355263157894737e-05,
      "loss": 0.2636,
      "step": 2750
    },
    {
      "epoch": 1.9616204690831558,
      "grad_norm": 6.433297157287598,
      "learning_rate": 1.9223684210526315e-05,
      "loss": 0.2334,
      "step": 2760
    },
    {
      "epoch": 1.968727789623312,
      "grad_norm": 7.017293930053711,
      "learning_rate": 1.9092105263157894e-05,
      "loss": 0.2404,
      "step": 2770
    },
    {
      "epoch": 1.9758351101634684,
      "grad_norm": 2.52168607711792,
      "learning_rate": 1.8960526315789475e-05,
      "loss": 0.2719,
      "step": 2780
    },
    {
      "epoch": 1.9829424307036247,
      "grad_norm": 7.672648906707764,
      "learning_rate": 1.8828947368421053e-05,
      "loss": 0.2256,
      "step": 2790
    },
    {
      "epoch": 1.9900497512437811,
      "grad_norm": 5.944643020629883,
      "learning_rate": 1.869736842105263e-05,
      "loss": 0.2772,
      "step": 2800
    },
    {
      "epoch": 1.9971570717839375,
      "grad_norm": 2.0278024673461914,
      "learning_rate": 1.856578947368421e-05,
      "loss": 0.2465,
      "step": 2810
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8976,
      "eval_f1": 0.9002338269680438,
      "eval_loss": 0.24928808212280273,
      "eval_precision": 0.8776595744680851,
      "eval_recall": 0.924,
      "eval_runtime": 26.3427,
      "eval_samples_per_second": 94.903,
      "eval_steps_per_second": 5.96,
      "step": 2814
    },
    {
      "epoch": 2.0042643923240937,
      "grad_norm": 3.7824909687042236,
      "learning_rate": 1.843421052631579e-05,
      "loss": 0.2121,
      "step": 2820
    },
    {
      "epoch": 2.0113717128642503,
      "grad_norm": 3.1262409687042236,
      "learning_rate": 1.830263157894737e-05,
      "loss": 0.2518,
      "step": 2830
    },
    {
      "epoch": 2.0184790334044065,
      "grad_norm": 6.990069389343262,
      "learning_rate": 1.8171052631578948e-05,
      "loss": 0.1961,
      "step": 2840
    },
    {
      "epoch": 2.025586353944563,
      "grad_norm": 3.173215627670288,
      "learning_rate": 1.803947368421053e-05,
      "loss": 0.1833,
      "step": 2850
    },
    {
      "epoch": 2.0326936744847193,
      "grad_norm": 1.4439399242401123,
      "learning_rate": 1.7907894736842108e-05,
      "loss": 0.193,
      "step": 2860
    },
    {
      "epoch": 2.0398009950248754,
      "grad_norm": 6.759960651397705,
      "learning_rate": 1.7776315789473686e-05,
      "loss": 0.317,
      "step": 2870
    },
    {
      "epoch": 2.046908315565032,
      "grad_norm": 3.301701545715332,
      "learning_rate": 1.7644736842105264e-05,
      "loss": 0.1497,
      "step": 2880
    },
    {
      "epoch": 2.0540156361051882,
      "grad_norm": 3.8743932247161865,
      "learning_rate": 1.7513157894736843e-05,
      "loss": 0.2853,
      "step": 2890
    },
    {
      "epoch": 2.061122956645345,
      "grad_norm": 1.8652968406677246,
      "learning_rate": 1.738157894736842e-05,
      "loss": 0.2863,
      "step": 2900
    },
    {
      "epoch": 2.068230277185501,
      "grad_norm": 5.673964977264404,
      "learning_rate": 1.725e-05,
      "loss": 0.1799,
      "step": 2910
    },
    {
      "epoch": 2.0753375977256576,
      "grad_norm": 9.417023658752441,
      "learning_rate": 1.711842105263158e-05,
      "loss": 0.2337,
      "step": 2920
    },
    {
      "epoch": 2.082444918265814,
      "grad_norm": 3.535398483276367,
      "learning_rate": 1.698684210526316e-05,
      "loss": 0.2441,
      "step": 2930
    },
    {
      "epoch": 2.08955223880597,
      "grad_norm": 4.263307094573975,
      "learning_rate": 1.6855263157894737e-05,
      "loss": 0.1723,
      "step": 2940
    },
    {
      "epoch": 2.0966595593461266,
      "grad_norm": 2.8005778789520264,
      "learning_rate": 1.6723684210526316e-05,
      "loss": 0.2036,
      "step": 2950
    },
    {
      "epoch": 2.1037668798862827,
      "grad_norm": 2.8049144744873047,
      "learning_rate": 1.6592105263157894e-05,
      "loss": 0.2472,
      "step": 2960
    },
    {
      "epoch": 2.1108742004264394,
      "grad_norm": 2.8411121368408203,
      "learning_rate": 1.6460526315789472e-05,
      "loss": 0.247,
      "step": 2970
    },
    {
      "epoch": 2.1179815209665955,
      "grad_norm": 5.261236667633057,
      "learning_rate": 1.6328947368421054e-05,
      "loss": 0.2076,
      "step": 2980
    },
    {
      "epoch": 2.125088841506752,
      "grad_norm": 3.4260060787200928,
      "learning_rate": 1.6197368421052632e-05,
      "loss": 0.1684,
      "step": 2990
    },
    {
      "epoch": 2.1321961620469083,
      "grad_norm": 2.1751222610473633,
      "learning_rate": 1.606578947368421e-05,
      "loss": 0.2267,
      "step": 3000
    },
    {
      "epoch": 2.1393034825870645,
      "grad_norm": 3.088998794555664,
      "learning_rate": 1.5934210526315792e-05,
      "loss": 0.2415,
      "step": 3010
    },
    {
      "epoch": 2.146410803127221,
      "grad_norm": 7.731764793395996,
      "learning_rate": 1.580263157894737e-05,
      "loss": 0.1926,
      "step": 3020
    },
    {
      "epoch": 2.1535181236673773,
      "grad_norm": 2.717984676361084,
      "learning_rate": 1.5671052631578948e-05,
      "loss": 0.2123,
      "step": 3030
    },
    {
      "epoch": 2.160625444207534,
      "grad_norm": 1.7322643995285034,
      "learning_rate": 1.5539473684210527e-05,
      "loss": 0.2706,
      "step": 3040
    },
    {
      "epoch": 2.16773276474769,
      "grad_norm": 7.752804279327393,
      "learning_rate": 1.5407894736842108e-05,
      "loss": 0.26,
      "step": 3050
    },
    {
      "epoch": 2.1748400852878467,
      "grad_norm": 3.545968770980835,
      "learning_rate": 1.5276315789473686e-05,
      "loss": 0.3031,
      "step": 3060
    },
    {
      "epoch": 2.181947405828003,
      "grad_norm": 1.6804028749465942,
      "learning_rate": 1.5144736842105265e-05,
      "loss": 0.1407,
      "step": 3070
    },
    {
      "epoch": 2.189054726368159,
      "grad_norm": 2.4729979038238525,
      "learning_rate": 1.5013157894736843e-05,
      "loss": 0.1982,
      "step": 3080
    },
    {
      "epoch": 2.1961620469083156,
      "grad_norm": 7.814938068389893,
      "learning_rate": 1.4881578947368421e-05,
      "loss": 0.2478,
      "step": 3090
    },
    {
      "epoch": 2.203269367448472,
      "grad_norm": 3.723757743835449,
      "learning_rate": 1.475e-05,
      "loss": 0.1848,
      "step": 3100
    },
    {
      "epoch": 2.2103766879886284,
      "grad_norm": 3.7189297676086426,
      "learning_rate": 1.4618421052631578e-05,
      "loss": 0.1811,
      "step": 3110
    },
    {
      "epoch": 2.2174840085287846,
      "grad_norm": 2.589812994003296,
      "learning_rate": 1.448684210526316e-05,
      "loss": 0.1864,
      "step": 3120
    },
    {
      "epoch": 2.224591329068941,
      "grad_norm": 3.0593185424804688,
      "learning_rate": 1.4355263157894738e-05,
      "loss": 0.2688,
      "step": 3130
    },
    {
      "epoch": 2.2316986496090974,
      "grad_norm": 3.3359758853912354,
      "learning_rate": 1.4223684210526317e-05,
      "loss": 0.402,
      "step": 3140
    },
    {
      "epoch": 2.2388059701492535,
      "grad_norm": 2.8078222274780273,
      "learning_rate": 1.4092105263157896e-05,
      "loss": 0.2581,
      "step": 3150
    },
    {
      "epoch": 2.24591329068941,
      "grad_norm": 4.653193950653076,
      "learning_rate": 1.3960526315789474e-05,
      "loss": 0.1851,
      "step": 3160
    },
    {
      "epoch": 2.2530206112295663,
      "grad_norm": 4.087031841278076,
      "learning_rate": 1.3828947368421052e-05,
      "loss": 0.185,
      "step": 3170
    },
    {
      "epoch": 2.260127931769723,
      "grad_norm": 1.2446372509002686,
      "learning_rate": 1.369736842105263e-05,
      "loss": 0.1746,
      "step": 3180
    },
    {
      "epoch": 2.267235252309879,
      "grad_norm": 0.5201845169067383,
      "learning_rate": 1.3565789473684212e-05,
      "loss": 0.2292,
      "step": 3190
    },
    {
      "epoch": 2.2743425728500357,
      "grad_norm": 4.221850395202637,
      "learning_rate": 1.343421052631579e-05,
      "loss": 0.1909,
      "step": 3200
    },
    {
      "epoch": 2.281449893390192,
      "grad_norm": 2.1959073543548584,
      "learning_rate": 1.3302631578947369e-05,
      "loss": 0.2828,
      "step": 3210
    },
    {
      "epoch": 2.288557213930348,
      "grad_norm": 2.3022968769073486,
      "learning_rate": 1.3171052631578948e-05,
      "loss": 0.2548,
      "step": 3220
    },
    {
      "epoch": 2.2956645344705047,
      "grad_norm": 0.9172477722167969,
      "learning_rate": 1.3039473684210527e-05,
      "loss": 0.199,
      "step": 3230
    },
    {
      "epoch": 2.302771855010661,
      "grad_norm": 0.42900633811950684,
      "learning_rate": 1.2907894736842105e-05,
      "loss": 0.2651,
      "step": 3240
    },
    {
      "epoch": 2.3098791755508175,
      "grad_norm": 4.86298131942749,
      "learning_rate": 1.2776315789473683e-05,
      "loss": 0.2549,
      "step": 3250
    },
    {
      "epoch": 2.3169864960909736,
      "grad_norm": 6.019127368927002,
      "learning_rate": 1.2644736842105265e-05,
      "loss": 0.2618,
      "step": 3260
    },
    {
      "epoch": 2.3240938166311302,
      "grad_norm": 1.969814658164978,
      "learning_rate": 1.2513157894736843e-05,
      "loss": 0.2962,
      "step": 3270
    },
    {
      "epoch": 2.3312011371712864,
      "grad_norm": 3.3508191108703613,
      "learning_rate": 1.2381578947368421e-05,
      "loss": 0.2026,
      "step": 3280
    },
    {
      "epoch": 2.3383084577114426,
      "grad_norm": 3.9597582817077637,
      "learning_rate": 1.225e-05,
      "loss": 0.2277,
      "step": 3290
    },
    {
      "epoch": 2.345415778251599,
      "grad_norm": 4.9375,
      "learning_rate": 1.211842105263158e-05,
      "loss": 0.2378,
      "step": 3300
    },
    {
      "epoch": 2.3525230987917554,
      "grad_norm": 2.847933530807495,
      "learning_rate": 1.198684210526316e-05,
      "loss": 0.169,
      "step": 3310
    },
    {
      "epoch": 2.359630419331912,
      "grad_norm": 3.018151044845581,
      "learning_rate": 1.1855263157894738e-05,
      "loss": 0.2806,
      "step": 3320
    },
    {
      "epoch": 2.366737739872068,
      "grad_norm": 2.892395257949829,
      "learning_rate": 1.1723684210526316e-05,
      "loss": 0.2838,
      "step": 3330
    },
    {
      "epoch": 2.3738450604122248,
      "grad_norm": 7.19207239151001,
      "learning_rate": 1.1592105263157896e-05,
      "loss": 0.2991,
      "step": 3340
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 2.6632938385009766,
      "learning_rate": 1.1460526315789474e-05,
      "loss": 0.2588,
      "step": 3350
    },
    {
      "epoch": 2.388059701492537,
      "grad_norm": 3.941638231277466,
      "learning_rate": 1.1328947368421052e-05,
      "loss": 0.1919,
      "step": 3360
    },
    {
      "epoch": 2.3951670220326937,
      "grad_norm": 3.2250044345855713,
      "learning_rate": 1.1197368421052632e-05,
      "loss": 0.2283,
      "step": 3370
    },
    {
      "epoch": 2.40227434257285,
      "grad_norm": 0.8695081472396851,
      "learning_rate": 1.106578947368421e-05,
      "loss": 0.1573,
      "step": 3380
    },
    {
      "epoch": 2.4093816631130065,
      "grad_norm": 7.1961750984191895,
      "learning_rate": 1.093421052631579e-05,
      "loss": 0.243,
      "step": 3390
    },
    {
      "epoch": 2.4164889836531627,
      "grad_norm": 4.66798210144043,
      "learning_rate": 1.0802631578947369e-05,
      "loss": 0.1874,
      "step": 3400
    },
    {
      "epoch": 2.4235963041933193,
      "grad_norm": 2.1238441467285156,
      "learning_rate": 1.0671052631578949e-05,
      "loss": 0.2291,
      "step": 3410
    },
    {
      "epoch": 2.4307036247334755,
      "grad_norm": 4.283474445343018,
      "learning_rate": 1.0539473684210527e-05,
      "loss": 0.2311,
      "step": 3420
    },
    {
      "epoch": 2.4378109452736316,
      "grad_norm": 3.9645628929138184,
      "learning_rate": 1.0407894736842105e-05,
      "loss": 0.2175,
      "step": 3430
    },
    {
      "epoch": 2.4449182658137882,
      "grad_norm": 3.4725587368011475,
      "learning_rate": 1.0276315789473685e-05,
      "loss": 0.1647,
      "step": 3440
    },
    {
      "epoch": 2.4520255863539444,
      "grad_norm": 2.833048105239868,
      "learning_rate": 1.0144736842105263e-05,
      "loss": 0.1346,
      "step": 3450
    },
    {
      "epoch": 2.459132906894101,
      "grad_norm": 4.021615505218506,
      "learning_rate": 1.0013157894736842e-05,
      "loss": 0.3118,
      "step": 3460
    },
    {
      "epoch": 2.466240227434257,
      "grad_norm": 1.7461493015289307,
      "learning_rate": 9.881578947368422e-06,
      "loss": 0.176,
      "step": 3470
    },
    {
      "epoch": 2.473347547974414,
      "grad_norm": 4.412519931793213,
      "learning_rate": 9.750000000000002e-06,
      "loss": 0.2605,
      "step": 3480
    },
    {
      "epoch": 2.48045486851457,
      "grad_norm": 1.796493411064148,
      "learning_rate": 9.61842105263158e-06,
      "loss": 0.279,
      "step": 3490
    },
    {
      "epoch": 2.487562189054726,
      "grad_norm": 2.2324633598327637,
      "learning_rate": 9.486842105263158e-06,
      "loss": 0.1955,
      "step": 3500
    },
    {
      "epoch": 2.4946695095948828,
      "grad_norm": 2.005673408508301,
      "learning_rate": 9.355263157894738e-06,
      "loss": 0.2074,
      "step": 3510
    },
    {
      "epoch": 2.501776830135039,
      "grad_norm": 2.2809386253356934,
      "learning_rate": 9.223684210526316e-06,
      "loss": 0.2893,
      "step": 3520
    },
    {
      "epoch": 2.5088841506751955,
      "grad_norm": 1.9121639728546143,
      "learning_rate": 9.092105263157894e-06,
      "loss": 0.2269,
      "step": 3530
    },
    {
      "epoch": 2.5159914712153517,
      "grad_norm": 4.8140645027160645,
      "learning_rate": 8.960526315789474e-06,
      "loss": 0.3292,
      "step": 3540
    },
    {
      "epoch": 2.5230987917555083,
      "grad_norm": 1.714698076248169,
      "learning_rate": 8.828947368421053e-06,
      "loss": 0.1852,
      "step": 3550
    },
    {
      "epoch": 2.5302061122956645,
      "grad_norm": 4.593472003936768,
      "learning_rate": 8.697368421052633e-06,
      "loss": 0.1695,
      "step": 3560
    },
    {
      "epoch": 2.5373134328358207,
      "grad_norm": 0.9872276782989502,
      "learning_rate": 8.56578947368421e-06,
      "loss": 0.1964,
      "step": 3570
    },
    {
      "epoch": 2.5444207533759773,
      "grad_norm": 2.2164227962493896,
      "learning_rate": 8.43421052631579e-06,
      "loss": 0.1802,
      "step": 3580
    },
    {
      "epoch": 2.5515280739161335,
      "grad_norm": 5.261941909790039,
      "learning_rate": 8.302631578947369e-06,
      "loss": 0.3066,
      "step": 3590
    },
    {
      "epoch": 2.55863539445629,
      "grad_norm": 2.8460967540740967,
      "learning_rate": 8.171052631578947e-06,
      "loss": 0.203,
      "step": 3600
    },
    {
      "epoch": 2.5657427149964462,
      "grad_norm": 5.031380653381348,
      "learning_rate": 8.039473684210527e-06,
      "loss": 0.2329,
      "step": 3610
    },
    {
      "epoch": 2.572850035536603,
      "grad_norm": 4.025640487670898,
      "learning_rate": 7.907894736842105e-06,
      "loss": 0.1997,
      "step": 3620
    },
    {
      "epoch": 2.579957356076759,
      "grad_norm": 3.4785878658294678,
      "learning_rate": 7.776315789473684e-06,
      "loss": 0.2588,
      "step": 3630
    },
    {
      "epoch": 2.587064676616915,
      "grad_norm": 3.728511095046997,
      "learning_rate": 7.644736842105264e-06,
      "loss": 0.2356,
      "step": 3640
    },
    {
      "epoch": 2.594171997157072,
      "grad_norm": 2.881075620651245,
      "learning_rate": 7.513157894736843e-06,
      "loss": 0.1619,
      "step": 3650
    },
    {
      "epoch": 2.6012793176972284,
      "grad_norm": 3.5957894325256348,
      "learning_rate": 7.381578947368421e-06,
      "loss": 0.1802,
      "step": 3660
    },
    {
      "epoch": 2.6083866382373846,
      "grad_norm": 3.965094566345215,
      "learning_rate": 7.25e-06,
      "loss": 0.2219,
      "step": 3670
    },
    {
      "epoch": 2.6154939587775408,
      "grad_norm": 3.0109424591064453,
      "learning_rate": 7.11842105263158e-06,
      "loss": 0.2314,
      "step": 3680
    },
    {
      "epoch": 2.6226012793176974,
      "grad_norm": 3.5385866165161133,
      "learning_rate": 6.986842105263158e-06,
      "loss": 0.1915,
      "step": 3690
    },
    {
      "epoch": 2.6297085998578535,
      "grad_norm": 4.32899808883667,
      "learning_rate": 6.8552631578947365e-06,
      "loss": 0.2134,
      "step": 3700
    },
    {
      "epoch": 2.6368159203980097,
      "grad_norm": 4.161020755767822,
      "learning_rate": 6.723684210526316e-06,
      "loss": 0.2656,
      "step": 3710
    },
    {
      "epoch": 2.6439232409381663,
      "grad_norm": 2.4553897380828857,
      "learning_rate": 6.5921052631578955e-06,
      "loss": 0.1772,
      "step": 3720
    },
    {
      "epoch": 2.651030561478323,
      "grad_norm": 2.682830333709717,
      "learning_rate": 6.460526315789474e-06,
      "loss": 0.1702,
      "step": 3730
    },
    {
      "epoch": 2.658137882018479,
      "grad_norm": 3.265897512435913,
      "learning_rate": 6.328947368421052e-06,
      "loss": 0.2296,
      "step": 3740
    },
    {
      "epoch": 2.6652452025586353,
      "grad_norm": 5.044548988342285,
      "learning_rate": 6.197368421052632e-06,
      "loss": 0.2882,
      "step": 3750
    },
    {
      "epoch": 2.672352523098792,
      "grad_norm": 3.578486204147339,
      "learning_rate": 6.065789473684211e-06,
      "loss": 0.1652,
      "step": 3760
    },
    {
      "epoch": 2.679459843638948,
      "grad_norm": 4.976192474365234,
      "learning_rate": 5.93421052631579e-06,
      "loss": 0.2024,
      "step": 3770
    },
    {
      "epoch": 2.6865671641791042,
      "grad_norm": 9.12263298034668,
      "learning_rate": 5.802631578947368e-06,
      "loss": 0.2244,
      "step": 3780
    },
    {
      "epoch": 2.693674484719261,
      "grad_norm": 4.507278919219971,
      "learning_rate": 5.6710526315789475e-06,
      "loss": 0.2949,
      "step": 3790
    },
    {
      "epoch": 2.7007818052594175,
      "grad_norm": 2.981192111968994,
      "learning_rate": 5.5394736842105266e-06,
      "loss": 0.1905,
      "step": 3800
    },
    {
      "epoch": 2.7078891257995736,
      "grad_norm": 2.952953577041626,
      "learning_rate": 5.407894736842106e-06,
      "loss": 0.269,
      "step": 3810
    },
    {
      "epoch": 2.71499644633973,
      "grad_norm": 9.009559631347656,
      "learning_rate": 5.276315789473685e-06,
      "loss": 0.2722,
      "step": 3820
    },
    {
      "epoch": 2.7221037668798864,
      "grad_norm": 3.7622416019439697,
      "learning_rate": 5.144736842105263e-06,
      "loss": 0.1799,
      "step": 3830
    },
    {
      "epoch": 2.7292110874200426,
      "grad_norm": 3.5697643756866455,
      "learning_rate": 5.013157894736843e-06,
      "loss": 0.116,
      "step": 3840
    },
    {
      "epoch": 2.7363184079601988,
      "grad_norm": 5.584956169128418,
      "learning_rate": 4.881578947368421e-06,
      "loss": 0.227,
      "step": 3850
    },
    {
      "epoch": 2.7434257285003554,
      "grad_norm": 4.872364044189453,
      "learning_rate": 4.75e-06,
      "loss": 0.2189,
      "step": 3860
    },
    {
      "epoch": 2.750533049040512,
      "grad_norm": 3.4222278594970703,
      "learning_rate": 4.618421052631579e-06,
      "loss": 0.2272,
      "step": 3870
    },
    {
      "epoch": 2.757640369580668,
      "grad_norm": 6.575922012329102,
      "learning_rate": 4.4868421052631584e-06,
      "loss": 0.127,
      "step": 3880
    },
    {
      "epoch": 2.7647476901208243,
      "grad_norm": 8.231864929199219,
      "learning_rate": 4.3552631578947375e-06,
      "loss": 0.2465,
      "step": 3890
    },
    {
      "epoch": 2.771855010660981,
      "grad_norm": 3.710655689239502,
      "learning_rate": 4.223684210526316e-06,
      "loss": 0.2041,
      "step": 3900
    },
    {
      "epoch": 2.778962331201137,
      "grad_norm": 7.584555149078369,
      "learning_rate": 4.092105263157895e-06,
      "loss": 0.2769,
      "step": 3910
    },
    {
      "epoch": 2.7860696517412933,
      "grad_norm": 5.017050743103027,
      "learning_rate": 3.960526315789474e-06,
      "loss": 0.2361,
      "step": 3920
    },
    {
      "epoch": 2.79317697228145,
      "grad_norm": 5.416184902191162,
      "learning_rate": 3.828947368421053e-06,
      "loss": 0.2968,
      "step": 3930
    },
    {
      "epoch": 2.8002842928216065,
      "grad_norm": 6.169817924499512,
      "learning_rate": 3.697368421052632e-06,
      "loss": 0.2483,
      "step": 3940
    },
    {
      "epoch": 2.8073916133617627,
      "grad_norm": 4.16762638092041,
      "learning_rate": 3.5657894736842104e-06,
      "loss": 0.1848,
      "step": 3950
    },
    {
      "epoch": 2.814498933901919,
      "grad_norm": 2.615785598754883,
      "learning_rate": 3.43421052631579e-06,
      "loss": 0.214,
      "step": 3960
    },
    {
      "epoch": 2.8216062544420755,
      "grad_norm": 2.827967882156372,
      "learning_rate": 3.302631578947368e-06,
      "loss": 0.2457,
      "step": 3970
    },
    {
      "epoch": 2.8287135749822316,
      "grad_norm": 1.992977499961853,
      "learning_rate": 3.1710526315789477e-06,
      "loss": 0.2543,
      "step": 3980
    },
    {
      "epoch": 2.835820895522388,
      "grad_norm": 1.2479099035263062,
      "learning_rate": 3.0394736842105263e-06,
      "loss": 0.2013,
      "step": 3990
    },
    {
      "epoch": 2.8429282160625444,
      "grad_norm": 3.984912633895874,
      "learning_rate": 2.9078947368421054e-06,
      "loss": 0.1593,
      "step": 4000
    },
    {
      "epoch": 2.850035536602701,
      "grad_norm": 2.2386674880981445,
      "learning_rate": 2.7763157894736845e-06,
      "loss": 0.2172,
      "step": 4010
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 6.767140865325928,
      "learning_rate": 2.644736842105263e-06,
      "loss": 0.3472,
      "step": 4020
    },
    {
      "epoch": 2.8642501776830134,
      "grad_norm": 1.7278721332550049,
      "learning_rate": 2.5131578947368423e-06,
      "loss": 0.2002,
      "step": 4030
    },
    {
      "epoch": 2.87135749822317,
      "grad_norm": 1.1671549081802368,
      "learning_rate": 2.381578947368421e-06,
      "loss": 0.1222,
      "step": 4040
    },
    {
      "epoch": 2.878464818763326,
      "grad_norm": 5.6302032470703125,
      "learning_rate": 2.25e-06,
      "loss": 0.1433,
      "step": 4050
    },
    {
      "epoch": 2.8855721393034823,
      "grad_norm": 3.648047924041748,
      "learning_rate": 2.1184210526315787e-06,
      "loss": 0.2568,
      "step": 4060
    },
    {
      "epoch": 2.892679459843639,
      "grad_norm": 3.0910263061523438,
      "learning_rate": 1.9868421052631582e-06,
      "loss": 0.283,
      "step": 4070
    },
    {
      "epoch": 2.8997867803837956,
      "grad_norm": 4.106494903564453,
      "learning_rate": 1.855263157894737e-06,
      "loss": 0.2385,
      "step": 4080
    },
    {
      "epoch": 2.9068941009239517,
      "grad_norm": 1.2018928527832031,
      "learning_rate": 1.7236842105263158e-06,
      "loss": 0.3118,
      "step": 4090
    },
    {
      "epoch": 2.914001421464108,
      "grad_norm": 1.6592694520950317,
      "learning_rate": 1.5921052631578947e-06,
      "loss": 0.1817,
      "step": 4100
    },
    {
      "epoch": 2.9211087420042645,
      "grad_norm": 3.54015851020813,
      "learning_rate": 1.4605263157894738e-06,
      "loss": 0.1655,
      "step": 4110
    },
    {
      "epoch": 2.9282160625444207,
      "grad_norm": 4.257242679595947,
      "learning_rate": 1.3289473684210526e-06,
      "loss": 0.2734,
      "step": 4120
    },
    {
      "epoch": 2.935323383084577,
      "grad_norm": 3.0828514099121094,
      "learning_rate": 1.1973684210526315e-06,
      "loss": 0.175,
      "step": 4130
    },
    {
      "epoch": 2.9424307036247335,
      "grad_norm": 6.584222316741943,
      "learning_rate": 1.0657894736842106e-06,
      "loss": 0.1947,
      "step": 4140
    },
    {
      "epoch": 2.94953802416489,
      "grad_norm": 3.0171713829040527,
      "learning_rate": 9.342105263157895e-07,
      "loss": 0.1393,
      "step": 4150
    },
    {
      "epoch": 2.9566453447050463,
      "grad_norm": 2.0391571521759033,
      "learning_rate": 8.026315789473684e-07,
      "loss": 0.1806,
      "step": 4160
    },
    {
      "epoch": 2.9637526652452024,
      "grad_norm": 0.9713953733444214,
      "learning_rate": 6.710526315789475e-07,
      "loss": 0.1389,
      "step": 4170
    },
    {
      "epoch": 2.970859985785359,
      "grad_norm": 4.490094184875488,
      "learning_rate": 5.394736842105264e-07,
      "loss": 0.1721,
      "step": 4180
    },
    {
      "epoch": 2.977967306325515,
      "grad_norm": 2.6892952919006348,
      "learning_rate": 4.078947368421053e-07,
      "loss": 0.1067,
      "step": 4190
    },
    {
      "epoch": 2.9850746268656714,
      "grad_norm": 6.908121585845947,
      "learning_rate": 2.763157894736842e-07,
      "loss": 0.335,
      "step": 4200
    },
    {
      "epoch": 2.992181947405828,
      "grad_norm": 4.348384380340576,
      "learning_rate": 1.4473684210526318e-07,
      "loss": 0.1203,
      "step": 4210
    },
    {
      "epoch": 2.9992892679459846,
      "grad_norm": 4.635646343231201,
      "learning_rate": 1.3157894736842106e-08,
      "loss": 0.2486,
      "step": 4220
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.902,
      "eval_f1": 0.9024293110314616,
      "eval_loss": 0.2498101145029068,
      "eval_precision": 0.8984932593180016,
      "eval_recall": 0.9064,
      "eval_runtime": 26.2631,
      "eval_samples_per_second": 95.191,
      "eval_steps_per_second": 5.978,
      "step": 4221
    }
  ],
  "logging_steps": 10,
  "max_steps": 4221,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 9247792343040000.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
