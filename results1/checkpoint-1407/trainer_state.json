{
  "best_metric": 0.89,
  "best_model_checkpoint": "./results1/checkpoint-1407",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 1407,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007107320540156361,
      "grad_norm": 0.8181204199790955,
      "learning_rate": 1.187648456057007e-06,
      "loss": 0.7004,
      "step": 10
    },
    {
      "epoch": 0.014214641080312722,
      "grad_norm": 1.0279542207717896,
      "learning_rate": 2.375296912114014e-06,
      "loss": 0.6958,
      "step": 20
    },
    {
      "epoch": 0.021321961620469083,
      "grad_norm": 0.8940870761871338,
      "learning_rate": 3.5629453681710215e-06,
      "loss": 0.6875,
      "step": 30
    },
    {
      "epoch": 0.028429282160625444,
      "grad_norm": 0.857053279876709,
      "learning_rate": 4.750593824228028e-06,
      "loss": 0.6893,
      "step": 40
    },
    {
      "epoch": 0.03553660270078181,
      "grad_norm": 1.266706109046936,
      "learning_rate": 5.938242280285035e-06,
      "loss": 0.6863,
      "step": 50
    },
    {
      "epoch": 0.042643923240938165,
      "grad_norm": 0.9493836164474487,
      "learning_rate": 7.125890736342043e-06,
      "loss": 0.6844,
      "step": 60
    },
    {
      "epoch": 0.04975124378109453,
      "grad_norm": 0.9968581795692444,
      "learning_rate": 8.31353919239905e-06,
      "loss": 0.6927,
      "step": 70
    },
    {
      "epoch": 0.05685856432125089,
      "grad_norm": 0.7703754305839539,
      "learning_rate": 9.501187648456057e-06,
      "loss": 0.6892,
      "step": 80
    },
    {
      "epoch": 0.06396588486140725,
      "grad_norm": 1.190040111541748,
      "learning_rate": 1.0688836104513065e-05,
      "loss": 0.6839,
      "step": 90
    },
    {
      "epoch": 0.07107320540156362,
      "grad_norm": 1.089756965637207,
      "learning_rate": 1.187648456057007e-05,
      "loss": 0.6867,
      "step": 100
    },
    {
      "epoch": 0.07818052594171997,
      "grad_norm": 0.7433860898017883,
      "learning_rate": 1.3064133016627078e-05,
      "loss": 0.6729,
      "step": 110
    },
    {
      "epoch": 0.08528784648187633,
      "grad_norm": 0.9344238638877869,
      "learning_rate": 1.4251781472684086e-05,
      "loss": 0.6764,
      "step": 120
    },
    {
      "epoch": 0.0923951670220327,
      "grad_norm": 1.026196002960205,
      "learning_rate": 1.5439429928741092e-05,
      "loss": 0.6824,
      "step": 130
    },
    {
      "epoch": 0.09950248756218906,
      "grad_norm": 1.1045241355895996,
      "learning_rate": 1.66270783847981e-05,
      "loss": 0.6691,
      "step": 140
    },
    {
      "epoch": 0.10660980810234541,
      "grad_norm": 0.8705831170082092,
      "learning_rate": 1.7814726840855108e-05,
      "loss": 0.6713,
      "step": 150
    },
    {
      "epoch": 0.11371712864250177,
      "grad_norm": 1.0659359693527222,
      "learning_rate": 1.9002375296912114e-05,
      "loss": 0.6594,
      "step": 160
    },
    {
      "epoch": 0.12082444918265814,
      "grad_norm": 1.5173131227493286,
      "learning_rate": 2.0190023752969123e-05,
      "loss": 0.6474,
      "step": 170
    },
    {
      "epoch": 0.1279317697228145,
      "grad_norm": 2.0305075645446777,
      "learning_rate": 2.137767220902613e-05,
      "loss": 0.6248,
      "step": 180
    },
    {
      "epoch": 0.13503909026297087,
      "grad_norm": 1.3181008100509644,
      "learning_rate": 2.2565320665083135e-05,
      "loss": 0.5929,
      "step": 190
    },
    {
      "epoch": 0.14214641080312723,
      "grad_norm": 1.3646469116210938,
      "learning_rate": 2.375296912114014e-05,
      "loss": 0.5572,
      "step": 200
    },
    {
      "epoch": 0.14925373134328357,
      "grad_norm": 2.807896614074707,
      "learning_rate": 2.494061757719715e-05,
      "loss": 0.4975,
      "step": 210
    },
    {
      "epoch": 0.15636105188343993,
      "grad_norm": 3.3489198684692383,
      "learning_rate": 2.6128266033254157e-05,
      "loss": 0.4624,
      "step": 220
    },
    {
      "epoch": 0.1634683724235963,
      "grad_norm": 5.487392425537109,
      "learning_rate": 2.7315914489311166e-05,
      "loss": 0.3855,
      "step": 230
    },
    {
      "epoch": 0.17057569296375266,
      "grad_norm": 5.254972457885742,
      "learning_rate": 2.8503562945368172e-05,
      "loss": 0.3734,
      "step": 240
    },
    {
      "epoch": 0.17768301350390903,
      "grad_norm": 1.8933240175247192,
      "learning_rate": 2.9691211401425178e-05,
      "loss": 0.3944,
      "step": 250
    },
    {
      "epoch": 0.1847903340440654,
      "grad_norm": 4.456177234649658,
      "learning_rate": 3.0878859857482184e-05,
      "loss": 0.4172,
      "step": 260
    },
    {
      "epoch": 0.19189765458422176,
      "grad_norm": 1.598341703414917,
      "learning_rate": 3.20665083135392e-05,
      "loss": 0.3853,
      "step": 270
    },
    {
      "epoch": 0.19900497512437812,
      "grad_norm": 6.257580757141113,
      "learning_rate": 3.32541567695962e-05,
      "loss": 0.3628,
      "step": 280
    },
    {
      "epoch": 0.20611229566453448,
      "grad_norm": 2.7718470096588135,
      "learning_rate": 3.444180522565321e-05,
      "loss": 0.3328,
      "step": 290
    },
    {
      "epoch": 0.21321961620469082,
      "grad_norm": 4.024362564086914,
      "learning_rate": 3.5629453681710215e-05,
      "loss": 0.3519,
      "step": 300
    },
    {
      "epoch": 0.22032693674484718,
      "grad_norm": 4.726733684539795,
      "learning_rate": 3.681710213776722e-05,
      "loss": 0.2453,
      "step": 310
    },
    {
      "epoch": 0.22743425728500355,
      "grad_norm": 4.899835586547852,
      "learning_rate": 3.800475059382423e-05,
      "loss": 0.3468,
      "step": 320
    },
    {
      "epoch": 0.2345415778251599,
      "grad_norm": 2.7217540740966797,
      "learning_rate": 3.919239904988123e-05,
      "loss": 0.3005,
      "step": 330
    },
    {
      "epoch": 0.24164889836531628,
      "grad_norm": 6.257454872131348,
      "learning_rate": 4.0380047505938246e-05,
      "loss": 0.3682,
      "step": 340
    },
    {
      "epoch": 0.24875621890547264,
      "grad_norm": 2.2090303897857666,
      "learning_rate": 4.156769596199525e-05,
      "loss": 0.3873,
      "step": 350
    },
    {
      "epoch": 0.255863539445629,
      "grad_norm": 5.390707969665527,
      "learning_rate": 4.275534441805226e-05,
      "loss": 0.3325,
      "step": 360
    },
    {
      "epoch": 0.26297085998578534,
      "grad_norm": 2.519174337387085,
      "learning_rate": 4.394299287410927e-05,
      "loss": 0.2987,
      "step": 370
    },
    {
      "epoch": 0.27007818052594174,
      "grad_norm": 2.501490831375122,
      "learning_rate": 4.513064133016627e-05,
      "loss": 0.2898,
      "step": 380
    },
    {
      "epoch": 0.2771855010660981,
      "grad_norm": 2.2056262493133545,
      "learning_rate": 4.6318289786223276e-05,
      "loss": 0.3433,
      "step": 390
    },
    {
      "epoch": 0.28429282160625446,
      "grad_norm": 6.923454761505127,
      "learning_rate": 4.750593824228028e-05,
      "loss": 0.3164,
      "step": 400
    },
    {
      "epoch": 0.2914001421464108,
      "grad_norm": 9.64022159576416,
      "learning_rate": 4.8693586698337295e-05,
      "loss": 0.3755,
      "step": 410
    },
    {
      "epoch": 0.29850746268656714,
      "grad_norm": 4.991449356079102,
      "learning_rate": 4.98812351543943e-05,
      "loss": 0.2796,
      "step": 420
    },
    {
      "epoch": 0.30561478322672353,
      "grad_norm": 5.998867034912109,
      "learning_rate": 4.9881578947368425e-05,
      "loss": 0.3715,
      "step": 430
    },
    {
      "epoch": 0.31272210376687987,
      "grad_norm": 5.667739391326904,
      "learning_rate": 4.975e-05,
      "loss": 0.2542,
      "step": 440
    },
    {
      "epoch": 0.31982942430703626,
      "grad_norm": 5.550570487976074,
      "learning_rate": 4.961842105263158e-05,
      "loss": 0.3904,
      "step": 450
    },
    {
      "epoch": 0.3269367448471926,
      "grad_norm": 8.117775917053223,
      "learning_rate": 4.948684210526316e-05,
      "loss": 0.2519,
      "step": 460
    },
    {
      "epoch": 0.334044065387349,
      "grad_norm": 7.843630790710449,
      "learning_rate": 4.935526315789474e-05,
      "loss": 0.3189,
      "step": 470
    },
    {
      "epoch": 0.3411513859275053,
      "grad_norm": 2.288923978805542,
      "learning_rate": 4.9223684210526316e-05,
      "loss": 0.3157,
      "step": 480
    },
    {
      "epoch": 0.3482587064676617,
      "grad_norm": 1.9325124025344849,
      "learning_rate": 4.9092105263157894e-05,
      "loss": 0.3706,
      "step": 490
    },
    {
      "epoch": 0.35536602700781805,
      "grad_norm": 2.674156904220581,
      "learning_rate": 4.896052631578947e-05,
      "loss": 0.319,
      "step": 500
    },
    {
      "epoch": 0.3624733475479744,
      "grad_norm": 5.045976161956787,
      "learning_rate": 4.882894736842106e-05,
      "loss": 0.3339,
      "step": 510
    },
    {
      "epoch": 0.3695806680881308,
      "grad_norm": 3.9472484588623047,
      "learning_rate": 4.8697368421052636e-05,
      "loss": 0.2163,
      "step": 520
    },
    {
      "epoch": 0.3766879886282871,
      "grad_norm": 5.394717693328857,
      "learning_rate": 4.8565789473684214e-05,
      "loss": 0.4175,
      "step": 530
    },
    {
      "epoch": 0.3837953091684435,
      "grad_norm": 6.262406349182129,
      "learning_rate": 4.843421052631579e-05,
      "loss": 0.3121,
      "step": 540
    },
    {
      "epoch": 0.39090262970859985,
      "grad_norm": 6.164360046386719,
      "learning_rate": 4.830263157894737e-05,
      "loss": 0.3249,
      "step": 550
    },
    {
      "epoch": 0.39800995024875624,
      "grad_norm": 9.718866348266602,
      "learning_rate": 4.817105263157895e-05,
      "loss": 0.3576,
      "step": 560
    },
    {
      "epoch": 0.4051172707889126,
      "grad_norm": 5.971670150756836,
      "learning_rate": 4.803947368421053e-05,
      "loss": 0.3226,
      "step": 570
    },
    {
      "epoch": 0.41222459132906897,
      "grad_norm": 3.1125705242156982,
      "learning_rate": 4.7907894736842105e-05,
      "loss": 0.2725,
      "step": 580
    },
    {
      "epoch": 0.4193319118692253,
      "grad_norm": 4.04184627532959,
      "learning_rate": 4.7776315789473684e-05,
      "loss": 0.3089,
      "step": 590
    },
    {
      "epoch": 0.42643923240938164,
      "grad_norm": 2.561224937438965,
      "learning_rate": 4.764473684210526e-05,
      "loss": 0.325,
      "step": 600
    },
    {
      "epoch": 0.43354655294953803,
      "grad_norm": 3.3261706829071045,
      "learning_rate": 4.751315789473684e-05,
      "loss": 0.3446,
      "step": 610
    },
    {
      "epoch": 0.44065387348969437,
      "grad_norm": 3.924152135848999,
      "learning_rate": 4.738157894736842e-05,
      "loss": 0.2807,
      "step": 620
    },
    {
      "epoch": 0.44776119402985076,
      "grad_norm": 2.23335862159729,
      "learning_rate": 4.7249999999999997e-05,
      "loss": 0.3059,
      "step": 630
    },
    {
      "epoch": 0.4548685145700071,
      "grad_norm": 4.182961940765381,
      "learning_rate": 4.711842105263158e-05,
      "loss": 0.3992,
      "step": 640
    },
    {
      "epoch": 0.4619758351101635,
      "grad_norm": 4.688613414764404,
      "learning_rate": 4.698684210526316e-05,
      "loss": 0.3134,
      "step": 650
    },
    {
      "epoch": 0.4690831556503198,
      "grad_norm": 1.8492405414581299,
      "learning_rate": 4.685526315789474e-05,
      "loss": 0.2193,
      "step": 660
    },
    {
      "epoch": 0.47619047619047616,
      "grad_norm": 5.0105390548706055,
      "learning_rate": 4.6723684210526316e-05,
      "loss": 0.2758,
      "step": 670
    },
    {
      "epoch": 0.48329779673063256,
      "grad_norm": 6.5723958015441895,
      "learning_rate": 4.65921052631579e-05,
      "loss": 0.2321,
      "step": 680
    },
    {
      "epoch": 0.4904051172707889,
      "grad_norm": 7.94719934463501,
      "learning_rate": 4.646052631578948e-05,
      "loss": 0.3193,
      "step": 690
    },
    {
      "epoch": 0.4975124378109453,
      "grad_norm": 3.951179027557373,
      "learning_rate": 4.632894736842106e-05,
      "loss": 0.2433,
      "step": 700
    },
    {
      "epoch": 0.5046197583511016,
      "grad_norm": 4.8463311195373535,
      "learning_rate": 4.6197368421052636e-05,
      "loss": 0.2689,
      "step": 710
    },
    {
      "epoch": 0.511727078891258,
      "grad_norm": 3.1561691761016846,
      "learning_rate": 4.6065789473684214e-05,
      "loss": 0.3222,
      "step": 720
    },
    {
      "epoch": 0.5188343994314144,
      "grad_norm": 1.0864384174346924,
      "learning_rate": 4.593421052631579e-05,
      "loss": 0.1907,
      "step": 730
    },
    {
      "epoch": 0.5259417199715707,
      "grad_norm": 1.330297589302063,
      "learning_rate": 4.580263157894737e-05,
      "loss": 0.2139,
      "step": 740
    },
    {
      "epoch": 0.5330490405117271,
      "grad_norm": 1.2673184871673584,
      "learning_rate": 4.567105263157895e-05,
      "loss": 0.2246,
      "step": 750
    },
    {
      "epoch": 0.5401563610518835,
      "grad_norm": 3.660353422164917,
      "learning_rate": 4.553947368421053e-05,
      "loss": 0.333,
      "step": 760
    },
    {
      "epoch": 0.5472636815920398,
      "grad_norm": 1.6236813068389893,
      "learning_rate": 4.5407894736842106e-05,
      "loss": 0.3047,
      "step": 770
    },
    {
      "epoch": 0.5543710021321961,
      "grad_norm": 0.733258068561554,
      "learning_rate": 4.527631578947369e-05,
      "loss": 0.2031,
      "step": 780
    },
    {
      "epoch": 0.5614783226723525,
      "grad_norm": 6.871444225311279,
      "learning_rate": 4.514473684210527e-05,
      "loss": 0.3327,
      "step": 790
    },
    {
      "epoch": 0.5685856432125089,
      "grad_norm": 1.8644025325775146,
      "learning_rate": 4.501315789473685e-05,
      "loss": 0.3295,
      "step": 800
    },
    {
      "epoch": 0.5756929637526652,
      "grad_norm": 6.76733922958374,
      "learning_rate": 4.4881578947368425e-05,
      "loss": 0.347,
      "step": 810
    },
    {
      "epoch": 0.5828002842928216,
      "grad_norm": 3.8209919929504395,
      "learning_rate": 4.4750000000000004e-05,
      "loss": 0.3084,
      "step": 820
    },
    {
      "epoch": 0.589907604832978,
      "grad_norm": 2.0486080646514893,
      "learning_rate": 4.461842105263158e-05,
      "loss": 0.2658,
      "step": 830
    },
    {
      "epoch": 0.5970149253731343,
      "grad_norm": 8.4255952835083,
      "learning_rate": 4.448684210526316e-05,
      "loss": 0.2712,
      "step": 840
    },
    {
      "epoch": 0.6041222459132907,
      "grad_norm": 1.9007000923156738,
      "learning_rate": 4.435526315789474e-05,
      "loss": 0.2458,
      "step": 850
    },
    {
      "epoch": 0.6112295664534471,
      "grad_norm": 1.6504321098327637,
      "learning_rate": 4.4223684210526317e-05,
      "loss": 0.1856,
      "step": 860
    },
    {
      "epoch": 0.6183368869936035,
      "grad_norm": 3.5537304878234863,
      "learning_rate": 4.4092105263157895e-05,
      "loss": 0.3476,
      "step": 870
    },
    {
      "epoch": 0.6254442075337597,
      "grad_norm": 1.9437413215637207,
      "learning_rate": 4.396052631578947e-05,
      "loss": 0.3434,
      "step": 880
    },
    {
      "epoch": 0.6325515280739161,
      "grad_norm": 6.343731880187988,
      "learning_rate": 4.382894736842105e-05,
      "loss": 0.3709,
      "step": 890
    },
    {
      "epoch": 0.6396588486140725,
      "grad_norm": 1.0885382890701294,
      "learning_rate": 4.369736842105263e-05,
      "loss": 0.2641,
      "step": 900
    },
    {
      "epoch": 0.6467661691542289,
      "grad_norm": 3.1310012340545654,
      "learning_rate": 4.3565789473684215e-05,
      "loss": 0.2879,
      "step": 910
    },
    {
      "epoch": 0.6538734896943852,
      "grad_norm": 2.6443569660186768,
      "learning_rate": 4.343421052631579e-05,
      "loss": 0.2871,
      "step": 920
    },
    {
      "epoch": 0.6609808102345416,
      "grad_norm": 1.290907621383667,
      "learning_rate": 4.330263157894737e-05,
      "loss": 0.2255,
      "step": 930
    },
    {
      "epoch": 0.668088130774698,
      "grad_norm": 4.207393646240234,
      "learning_rate": 4.317105263157895e-05,
      "loss": 0.3429,
      "step": 940
    },
    {
      "epoch": 0.6751954513148543,
      "grad_norm": 2.4924087524414062,
      "learning_rate": 4.303947368421053e-05,
      "loss": 0.2385,
      "step": 950
    },
    {
      "epoch": 0.6823027718550106,
      "grad_norm": 2.008599042892456,
      "learning_rate": 4.2907894736842106e-05,
      "loss": 0.2812,
      "step": 960
    },
    {
      "epoch": 0.689410092395167,
      "grad_norm": 3.8274593353271484,
      "learning_rate": 4.2776315789473684e-05,
      "loss": 0.3223,
      "step": 970
    },
    {
      "epoch": 0.6965174129353234,
      "grad_norm": 1.7950327396392822,
      "learning_rate": 4.264473684210526e-05,
      "loss": 0.1991,
      "step": 980
    },
    {
      "epoch": 0.7036247334754797,
      "grad_norm": 10.735652923583984,
      "learning_rate": 4.251315789473684e-05,
      "loss": 0.2361,
      "step": 990
    },
    {
      "epoch": 0.7107320540156361,
      "grad_norm": 0.7412087321281433,
      "learning_rate": 4.2381578947368426e-05,
      "loss": 0.2064,
      "step": 1000
    },
    {
      "epoch": 0.7178393745557925,
      "grad_norm": 0.33822453022003174,
      "learning_rate": 4.2250000000000004e-05,
      "loss": 0.2571,
      "step": 1010
    },
    {
      "epoch": 0.7249466950959488,
      "grad_norm": 9.132181167602539,
      "learning_rate": 4.211842105263158e-05,
      "loss": 0.421,
      "step": 1020
    },
    {
      "epoch": 0.7320540156361052,
      "grad_norm": 2.2566213607788086,
      "learning_rate": 4.198684210526316e-05,
      "loss": 0.2296,
      "step": 1030
    },
    {
      "epoch": 0.7391613361762616,
      "grad_norm": 2.5582404136657715,
      "learning_rate": 4.185526315789474e-05,
      "loss": 0.3279,
      "step": 1040
    },
    {
      "epoch": 0.746268656716418,
      "grad_norm": 2.088041067123413,
      "learning_rate": 4.1723684210526324e-05,
      "loss": 0.2284,
      "step": 1050
    },
    {
      "epoch": 0.7533759772565742,
      "grad_norm": 3.8046681880950928,
      "learning_rate": 4.15921052631579e-05,
      "loss": 0.2638,
      "step": 1060
    },
    {
      "epoch": 0.7604832977967306,
      "grad_norm": 1.6764944791793823,
      "learning_rate": 4.146052631578948e-05,
      "loss": 0.229,
      "step": 1070
    },
    {
      "epoch": 0.767590618336887,
      "grad_norm": 1.4182195663452148,
      "learning_rate": 4.132894736842106e-05,
      "loss": 0.2927,
      "step": 1080
    },
    {
      "epoch": 0.7746979388770433,
      "grad_norm": 2.1676807403564453,
      "learning_rate": 4.1197368421052636e-05,
      "loss": 0.1989,
      "step": 1090
    },
    {
      "epoch": 0.7818052594171997,
      "grad_norm": 7.187459468841553,
      "learning_rate": 4.1065789473684215e-05,
      "loss": 0.3146,
      "step": 1100
    },
    {
      "epoch": 0.7889125799573561,
      "grad_norm": 4.405439376831055,
      "learning_rate": 4.093421052631579e-05,
      "loss": 0.2824,
      "step": 1110
    },
    {
      "epoch": 0.7960199004975125,
      "grad_norm": 9.812396049499512,
      "learning_rate": 4.080263157894737e-05,
      "loss": 0.3045,
      "step": 1120
    },
    {
      "epoch": 0.8031272210376688,
      "grad_norm": 2.0270044803619385,
      "learning_rate": 4.067105263157895e-05,
      "loss": 0.2199,
      "step": 1130
    },
    {
      "epoch": 0.8102345415778252,
      "grad_norm": 3.854360580444336,
      "learning_rate": 4.053947368421053e-05,
      "loss": 0.2942,
      "step": 1140
    },
    {
      "epoch": 0.8173418621179815,
      "grad_norm": 2.1559250354766846,
      "learning_rate": 4.0407894736842106e-05,
      "loss": 0.2663,
      "step": 1150
    },
    {
      "epoch": 0.8244491826581379,
      "grad_norm": 3.538825273513794,
      "learning_rate": 4.0276315789473684e-05,
      "loss": 0.2786,
      "step": 1160
    },
    {
      "epoch": 0.8315565031982942,
      "grad_norm": 2.7436070442199707,
      "learning_rate": 4.014473684210526e-05,
      "loss": 0.2341,
      "step": 1170
    },
    {
      "epoch": 0.8386638237384506,
      "grad_norm": 3.6034693717956543,
      "learning_rate": 4.001315789473684e-05,
      "loss": 0.167,
      "step": 1180
    },
    {
      "epoch": 0.845771144278607,
      "grad_norm": 1.6641169786453247,
      "learning_rate": 3.9881578947368426e-05,
      "loss": 0.2372,
      "step": 1190
    },
    {
      "epoch": 0.8528784648187633,
      "grad_norm": 8.15063190460205,
      "learning_rate": 3.9750000000000004e-05,
      "loss": 0.4378,
      "step": 1200
    },
    {
      "epoch": 0.8599857853589197,
      "grad_norm": 1.3333150148391724,
      "learning_rate": 3.961842105263158e-05,
      "loss": 0.244,
      "step": 1210
    },
    {
      "epoch": 0.8670931058990761,
      "grad_norm": 2.7276203632354736,
      "learning_rate": 3.948684210526316e-05,
      "loss": 0.254,
      "step": 1220
    },
    {
      "epoch": 0.8742004264392325,
      "grad_norm": 4.079287528991699,
      "learning_rate": 3.935526315789474e-05,
      "loss": 0.2366,
      "step": 1230
    },
    {
      "epoch": 0.8813077469793887,
      "grad_norm": 2.838575601577759,
      "learning_rate": 3.922368421052632e-05,
      "loss": 0.2379,
      "step": 1240
    },
    {
      "epoch": 0.8884150675195451,
      "grad_norm": 1.3774826526641846,
      "learning_rate": 3.9092105263157895e-05,
      "loss": 0.2413,
      "step": 1250
    },
    {
      "epoch": 0.8955223880597015,
      "grad_norm": 1.1256725788116455,
      "learning_rate": 3.8960526315789473e-05,
      "loss": 0.2206,
      "step": 1260
    },
    {
      "epoch": 0.9026297085998578,
      "grad_norm": 5.647760391235352,
      "learning_rate": 3.882894736842105e-05,
      "loss": 0.3458,
      "step": 1270
    },
    {
      "epoch": 0.9097370291400142,
      "grad_norm": 2.3039329051971436,
      "learning_rate": 3.869736842105263e-05,
      "loss": 0.3205,
      "step": 1280
    },
    {
      "epoch": 0.9168443496801706,
      "grad_norm": 4.309289932250977,
      "learning_rate": 3.856578947368421e-05,
      "loss": 0.2834,
      "step": 1290
    },
    {
      "epoch": 0.923951670220327,
      "grad_norm": 3.118396282196045,
      "learning_rate": 3.8434210526315786e-05,
      "loss": 0.3476,
      "step": 1300
    },
    {
      "epoch": 0.9310589907604833,
      "grad_norm": 4.317744731903076,
      "learning_rate": 3.8302631578947365e-05,
      "loss": 0.3108,
      "step": 1310
    },
    {
      "epoch": 0.9381663113006397,
      "grad_norm": 3.824692726135254,
      "learning_rate": 3.817105263157895e-05,
      "loss": 0.2096,
      "step": 1320
    },
    {
      "epoch": 0.945273631840796,
      "grad_norm": 4.6562180519104,
      "learning_rate": 3.803947368421053e-05,
      "loss": 0.2047,
      "step": 1330
    },
    {
      "epoch": 0.9523809523809523,
      "grad_norm": 1.304869532585144,
      "learning_rate": 3.7907894736842106e-05,
      "loss": 0.2882,
      "step": 1340
    },
    {
      "epoch": 0.9594882729211087,
      "grad_norm": 4.33357048034668,
      "learning_rate": 3.7776315789473684e-05,
      "loss": 0.3279,
      "step": 1350
    },
    {
      "epoch": 0.9665955934612651,
      "grad_norm": 1.6882264614105225,
      "learning_rate": 3.764473684210526e-05,
      "loss": 0.2399,
      "step": 1360
    },
    {
      "epoch": 0.9737029140014215,
      "grad_norm": 5.81782865524292,
      "learning_rate": 3.751315789473685e-05,
      "loss": 0.2859,
      "step": 1370
    },
    {
      "epoch": 0.9808102345415778,
      "grad_norm": 3.4679417610168457,
      "learning_rate": 3.7381578947368426e-05,
      "loss": 0.3001,
      "step": 1380
    },
    {
      "epoch": 0.9879175550817342,
      "grad_norm": 2.9034414291381836,
      "learning_rate": 3.7250000000000004e-05,
      "loss": 0.3453,
      "step": 1390
    },
    {
      "epoch": 0.9950248756218906,
      "grad_norm": 2.6851634979248047,
      "learning_rate": 3.711842105263158e-05,
      "loss": 0.2579,
      "step": 1400
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.89,
      "eval_f1": 0.8925361469323955,
      "eval_loss": 0.25772756338119507,
      "eval_precision": 0.8724216959511077,
      "eval_recall": 0.9136,
      "eval_runtime": 26.2764,
      "eval_samples_per_second": 95.142,
      "eval_steps_per_second": 5.975,
      "step": 1407
    }
  ],
  "logging_steps": 10,
  "max_steps": 4221,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3082597447680000.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
